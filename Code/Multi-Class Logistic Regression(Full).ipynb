{"cells":[{"cell_type":"markdown","id":"5c0792da","metadata":{},"source":["### Importing Libraries"]},{"cell_type":"code","execution_count":28,"id":"9637b14e","metadata":{},"outputs":[],"source":["#import statements\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from pyspark.ml.feature import Bucketizer\n","\n","from pyspark.sql.functions import *\n","\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","spark.conf.set(\"spark.sql.caseSensitive\", \"true\")"]},{"cell_type":"code","execution_count":29,"id":"6e32d9d0","metadata":{},"outputs":[],"source":["spark = SparkSession.builder.enableHiveSupport().appName('AmazonData').getOrCreate()\n","sc = spark.sparkContext"]},{"cell_type":"code","execution_count":30,"id":"4efda457","metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":["[('spark.eventLog.enabled', 'true'),\n"," ('spark.dynamicAllocation.minExecutors', '1'),\n"," ('spark.driver.appUIAddress',\n","  'http://bigdataproject-m.us-central1-b.c.sustained-spark-343705.internal:40965'),\n"," ('spark.executor.memory', '5739m'),\n"," ('spark.kryoserializer.buffer.max', '2000M'),\n"," ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n"," ('spark.driver.maxResultSize', '0'),\n"," ('spark.yarn.unmanagedAM.enabled', 'true'),\n"," ('spark.sql.autoBroadcastJoinThreshold', '43m'),\n"," ('spark.app.id', 'application_1647288588217_0002'),\n"," ('spark.ui.filters',\n","  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n"," ('spark.repl.local.jars',\n","  'file:///root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.4.jar,file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar,file:///root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,file:///root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,file:///root/.ivy2/jars/com.navigamez_greex-1.0.jar,file:///root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,file:///root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,file:///root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,file:///root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,file:///root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,file:///root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,file:///root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,file:///root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.metrics.namespace',\n","  'app_name:${spark.app.name}.app_id:${spark.app.id}'),\n"," ('spark.hadoop.hive.execution.engine', 'mr'),\n"," ('spark.executorEnv.PYTHONPATH',\n","  '/usr/lib/spark/python/lib/py4j-0.10.9-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip<CPS>{{PWD}}/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.4.jar<CPS>{{PWD}}/com.typesafe_config-1.4.1.jar<CPS>{{PWD}}/org.rocksdb_rocksdbjni-6.5.3.jar<CPS>{{PWD}}/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar<CPS>{{PWD}}/com.github.universal-automata_liblevenshtein-3.0.0.jar<CPS>{{PWD}}/com.navigamez_greex-1.0.jar<CPS>{{PWD}}/org.json4s_json4s-ext_2.12-3.5.3.jar<CPS>{{PWD}}/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar<CPS>{{PWD}}/net.sf.trove4j_trove4j-3.0.3.jar<CPS>{{PWD}}/com.google.code.findbugs_annotations-3.0.1.jar<CPS>{{PWD}}/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar<CPS>{{PWD}}/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar<CPS>{{PWD}}/it.unimi.dsi_fastutil-7.0.12.jar<CPS>{{PWD}}/org.projectlombok_lombok-1.16.8.jar<CPS>{{PWD}}/org.slf4j_slf4j-api-1.7.21.jar<CPS>{{PWD}}/net.jcip_jcip-annotations-1.0.jar<CPS>{{PWD}}/com.google.code.findbugs_jsr305-3.0.1.jar<CPS>{{PWD}}/com.google.code.gson_gson-2.3.jar<CPS>{{PWD}}/dk.brics.automaton_automaton-1.11-8.jar<CPS>{{PWD}}/joda-time_joda-time-2.9.5.jar<CPS>{{PWD}}/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.executor.id', 'driver'),\n"," ('spark.app.name', 'PySparkShell'),\n"," ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version', '2'),\n"," ('spark.dynamicAllocation.maxExecutors', '10000'),\n"," ('spark.sql.catalogImplementation', 'hive'),\n"," ('spark.history.fs.logDirectory',\n","  'gs://dataproc-temp-us-central1-863987436357-pe32nzky/6c6a6e9e-c97c-44dd-a7e1-fdf52788bbaa/spark-job-history'),\n"," ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n"," ('spark.sql.cbo.enabled', 'true'),\n"," ('spark.yarn.historyServer.address', 'bigdataproject-m:18080'),\n"," ('spark.app.startTime', '1647290309838'),\n"," ('spark.submit.pyFiles',\n","  '/root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.4.jar,/root/.ivy2/jars/com.typesafe_config-1.4.1.jar,/root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,/root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,/root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,/root/.ivy2/jars/com.navigamez_greex-1.0.jar,/root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,/root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,/root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,/root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,/root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,/root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,/root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,/root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,/root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,/root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,/root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,/root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,/root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,/root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.sql.warehouse.dir', 'file:/spark-warehouse'),\n"," ('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.4'),\n"," ('spark.eventLog.dir',\n","  'gs://dataproc-temp-us-central1-863987436357-pe32nzky/6c6a6e9e-c97c-44dd-a7e1-fdf52788bbaa/spark-job-history'),\n"," ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n","  'http://bigdataproject-m:8088/proxy/application_1647288588217_0002'),\n"," ('spark.yarn.am.memory', '640m'),\n"," ('spark.yarn.dist.pyFiles',\n","  'file:///root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.4.jar,file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar,file:///root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,file:///root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,file:///root/.ivy2/jars/com.navigamez_greex-1.0.jar,file:///root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,file:///root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,file:///root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,file:///root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,file:///root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,file:///root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,file:///root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,file:///root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.driver.port', '40235'),\n"," ('spark.executor.instances', '2'),\n"," ('spark.serializer.objectStreamReset', '100'),\n"," ('spark.submit.deployMode', 'client'),\n"," ('spark.extraListeners',\n","  'com.google.cloud.spark.performance.DataprocMetricsListener'),\n"," ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n","  'bigdataproject-m'),\n"," ('spark.sql.cbo.joinReorder.enabled', 'true'),\n"," ('spark.shuffle.service.enabled', 'true'),\n"," ('spark.scheduler.mode', 'FAIR'),\n"," ('spark.sql.adaptive.enabled', 'true'),\n"," ('spark.yarn.jars', 'local:/usr/lib/spark/jars/*'),\n"," ('spark.scheduler.minRegisteredResourcesRatio', '0.0'),\n"," ('spark.executor.cores', '2'),\n"," ('spark.yarn.secondary.jars',\n","  'com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.4.jar,com.typesafe_config-1.4.1.jar,org.rocksdb_rocksdbjni-6.5.3.jar,com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,com.github.universal-automata_liblevenshtein-3.0.0.jar,com.navigamez_greex-1.0.jar,org.json4s_json4s-ext_2.12-3.5.3.jar,com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,net.sf.trove4j_trove4j-3.0.3.jar,com.google.code.findbugs_annotations-3.0.1.jar,com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,it.unimi.dsi_fastutil-7.0.12.jar,org.projectlombok_lombok-1.16.8.jar,org.slf4j_slf4j-api-1.7.21.jar,net.jcip_jcip-annotations-1.0.jar,com.google.code.findbugs_jsr305-3.0.1.jar,com.google.code.gson_gson-2.3.jar,dk.brics.automaton_automaton-1.11-8.jar,joda-time_joda-time-2.9.5.jar,org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.master', 'yarn'),\n"," ('spark.ui.port', '0'),\n"," ('spark.ui.proxyBase', '/proxy/application_1647288588217_0002'),\n"," ('spark.driver.host',\n","  'bigdataproject-m.us-central1-b.c.sustained-spark-343705.internal'),\n"," ('spark.rdd.compress', 'True'),\n"," ('spark.rpc.message.maxSize', '512'),\n"," ('spark.driver.memory', '3840m'),\n"," ('spark.dynamicAllocation.enabled', 'true'),\n"," ('spark.yarn.isPython', 'true'),\n"," ('spark.ui.showConsoleProgress', 'true'),\n"," ('spark.yarn.dist.jars',\n","  'file:///root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.4.jar,file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar,file:///root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,file:///root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,file:///root/.ivy2/jars/com.navigamez_greex-1.0.jar,file:///root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,file:///root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,file:///root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,file:///root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,file:///root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,file:///root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,file:///root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,file:///root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar')]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["spark.sparkContext.getConf().getAll()"]},{"cell_type":"markdown","id":"3a9a7723","metadata":{},"source":["### Importing Datasets"]},{"cell_type":"code","execution_count":31,"id":"aba1f229","metadata":{},"outputs":[],"source":["AF= 'gs://sunenabigdata/actaul_data_json/AMAZON_FASHION.json'\n","AB= 'gs://sunenabigdata/actaul_data_json/All_Beauty.json'\n","CSJ= 'gs://sunenabigdata/actaul_data_json/Clothing_Shoes_and_Jewelry.json'\n","LB= 'gs://sunenabigdata/actaul_data_json/Luxury_Beauty.json'\n","mAF= 'gs://sunenabigdata/meta_data_json/meta_AMAZON_FASHION.json'\n","mAB= 'gs://sunenabigdata/meta_data_json/meta_All_Beauty.json'\n","mCSJ= 'gs://sunenabigdata/meta_data_json/meta_Clothing_Shoes_and_Jewelry.json'\n","mLB= 'gs://sunenabigdata/meta_data_json/meta_Luxury_Beauty.json'"]},{"cell_type":"code","execution_count":32,"id":"8088257e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_AF = spark.read.json(AF)\n","df_AF = df_AF.withColumn(\"Category\", lit(\"Amazon Fashion\"))\n","df_AB = spark.read.json(AB)\n","df_AB = df_AB.withColumn(\"Category\", lit(\"All Beauty\"))\n","df_CSJ = spark.read.json(CSJ)\n","df_CSJ = df_CSJ.withColumn(\"Category\", lit(\"Clothing, Shoes and Jewelery\"))\n","df_LB= spark.read.json(LB)\n","df_LB = df_LB.withColumn(\"Category\", lit(\"Luxury Beauty\"))"]},{"cell_type":"code","execution_count":33,"id":"ca71eb3e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["mdf_AF = spark.read.json(mAF)\n","mdf_AB = spark.read.json(mAB)\n","mdf_CSJ = spark.read.json(mCSJ)\n","mdf_LB= spark.read.json(mLB)"]},{"cell_type":"code","execution_count":34,"id":"feb6565c","metadata":{},"outputs":[],"source":["df1_AF=df_AF.drop(\"reviewerName\",\"style\",\"image\")\n","df1_AB=df_AB.drop(\"reviewerName\",\"style\",\"image\")\n","df1_CSJ=df_CSJ.drop(\"reviewerName\",\"style\",\"image\")\n","df1_LB=df_LB.drop(\"reviewerName\",\"style\",\"image\")\n","\n","whole= df1_AF.union(df1_AB)\n","whole= whole.union(df1_CSJ)\n","whole=whole.union(df1_LB)"]},{"cell_type":"code","execution_count":35,"id":"a966462a","metadata":{},"outputs":[],"source":["#renaming asin column to productID, saving in a new dataframe called whole2\n","whole2 = whole.withColumnRenamed(\"asin\",\"productID\")"]},{"cell_type":"code","execution_count":36,"id":"0cea18d9","metadata":{},"outputs":[],"source":["mdf1_AF=mdf_AF.drop('also_buy','also_view', 'description', 'details', 'feature', 'fit',\n","                    'imageURL','imageURLHighRes', 'similar_item','tech1')\n","mdf1_AB=mdf_AB.drop('also_buy','also_view','category', 'description', 'details', 'feature', 'fit',\n","                    'imageURL','imageURLHighRes', 'main_cat','similar_item','tech1', 'tech2')\n","mdf1_CSJ=mdf_CSJ.drop('also_buy','also_view','category', 'description', 'details', 'feature', 'fit',\n","                    'imageURL','imageURLHighRes', 'main_cat','similar_item','tech1', 'tech2')\n","mdf1_LB=mdf_LB.drop('also_buy','also_view','category', 'description', 'details', 'feature', 'fit',\n","                    'imageURL','imageURLHighRes', 'main_cat','similar_item','tech1', 'tech2')\n","\n","m_whole= mdf1_AF.union(mdf1_AB)\n","m_whole= m_whole.union(mdf1_CSJ)\n","m_whole=m_whole.union(mdf1_LB)"]},{"cell_type":"code","execution_count":37,"id":"bf47ba7b","metadata":{},"outputs":[],"source":["finaldf= whole2.join(m_whole, whole2.productID == m_whole.asin, 'inner')\n","finaldf = finaldf.drop(\"asin\")"]},{"cell_type":"code","execution_count":38,"id":"40a3ba90","metadata":{},"outputs":[],"source":["finaldf = finaldf.select(concat(finaldf.productID, finaldf.reviewerID, finaldf.unixReviewTime).alias(\"uniqueID\"), \"*\")"]},{"cell_type":"code","execution_count":39,"id":"abde381a","metadata":{"scrolled":true},"outputs":[],"source":["finaldf = finaldf.dropDuplicates([\"uniqueID\"])"]},{"cell_type":"code","execution_count":40,"id":"c90a0bda","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["33464003"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["finaldf.count()"]},{"cell_type":"markdown","id":"710ae560","metadata":{},"source":["### 10 Core data -  Selecting Only products which have more than 10 reviews"]},{"cell_type":"code","execution_count":41,"id":"4227d158","metadata":{},"outputs":[],"source":["df=finaldf.groupBy(col('productID').alias('productID1')).count().orderBy(\"count\", ascending=False)"]},{"cell_type":"code","execution_count":42,"id":"fdf75ec8","metadata":{},"outputs":[],"source":["df2= finaldf.join(df, finaldf.productID == df.productID1, 'inner')"]},{"cell_type":"code","execution_count":43,"id":"48a366e6","metadata":{},"outputs":[],"source":["df2=df2.drop('productID1')"]},{"cell_type":"code","execution_count":44,"id":"88cd0fd7","metadata":{},"outputs":[],"source":["df3=df2.filter(df2['count']>9)"]},{"cell_type":"code","execution_count":45,"id":"c479bdb9","metadata":{},"outputs":[],"source":["main_final=df3.na.drop(subset=[\"reviewText\"])"]},{"cell_type":"code","execution_count":46,"id":"261ea36e","metadata":{},"outputs":[],"source":["df6= main_final.select('overall','reviewText')"]},{"cell_type":"code","execution_count":47,"id":"89be6cc5","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 175:=====================================================>(99 + 1) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+--------------------+\n","|overall|          reviewText|\n","+-------+--------------------+\n","|    5.0|It gives you a re...|\n","|    5.0|This accessory ki...|\n","|    3.0|Teeth weren't rea...|\n","|    5.0|         Great stuff|\n","|    4.0|the teeth made th...|\n","|    5.0|Good deal, really...|\n","|    5.0|Excellent deal fo...|\n","|    1.0|      Missing items.|\n","|    1.0|            Garbage!|\n","|    1.0|            Not good|\n","|    1.0|Wig is too dark, ...|\n","|    2.0|Ok product but cheap|\n","|    4.0|Over all very goo...|\n","|    4.0|I mostly bought t...|\n","|    2.0|The wig was a wil...|\n","|    4.0|The plastic glass...|\n","|    3.0|The wig was actua...|\n","|    5.0|Wig was great! Ot...|\n","|    1.0|When I received t...|\n","|    1.0|Wig sucks.  The t...|\n","+-------+--------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df6.show()"]},{"cell_type":"markdown","id":"6930e4c0","metadata":{},"source":["### Converting review text into Term Frequencies"]},{"cell_type":"code","execution_count":48,"id":"9ced4df5","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 206:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+--------------------+\n","|overall|               words|\n","+-------+--------------------+\n","|    2.0|[ok, product, but...|\n","|    1.0|[i, got, this, fo...|\n","|    3.0|[teeth, weren't, ...|\n","|    1.0|   [missing, items.]|\n","|    4.0|[the, teeth, made...|\n","+-------+--------------------+\n","only showing top 5 rows\n","\n","CPU times: user 216 ms, sys: 115 ms, total: 331 ms\n","Wall time: 2min 3s\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["%%time\n","from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n","\n","#tokenize words\n","tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n","df6 = tokenizer.transform(df6)\n","\n","#drop the redundant source column\n","df6= df6.drop(\"reviewText\")\n","df6.show(5)"]},{"cell_type":"code","execution_count":49,"id":"311d7fef","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 221:====================================================> (98 + 2) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+--------------------+\n","|overall|            filtered|\n","+-------+--------------------+\n","|    2.0|[ok, product, cheap]|\n","|    3.0|[wig, actually, b...|\n","|    4.0|[mostly, bought, ...|\n","|    1.0|[bought, go, cost...|\n","|    2.0|[wig, wild, mess,...|\n","+-------+--------------------+\n","only showing top 5 rows\n","\n","CPU times: user 266 ms, sys: 105 ms, total: 371 ms\n","Wall time: 1min 47s\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["%%time\n","from pyspark.ml.feature import StopWordsRemover\n","\n","#remove stop words\n","remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n","df6 = remover.transform(df6)\n","\n","#drop the redundant source column\n","df6= df6.drop(\"words\")\n","df6.show(5)"]},{"cell_type":"code","execution_count":50,"id":"9948fa93","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 267:=====================================================>(99 + 1) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|features                                                                                                                                                                                                                                                             |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|(20,[1,3,5,7,8,9,11,12,13,15,17,18],[1.8057870701235432,2.8108446955451796,2.534706635413931,2.0081336229444,0.6428947985542377,0.7409836504433677,1.925414184194805,2.3424631582315865,0.9339027639750275,3.0172391677258688,0.7955090789330362,1.0699140471901387])|\n","|(20,[2,4,8,13,16,17,18,19],[0.9652522100632906,0.9852533261550888,0.6428947985542377,1.867805527950055,1.0135963726534234,1.5910181578660725,2.1398280943802774,1.0290204357885293])                                                                                 |\n","|(20,[0,2,6,7,8,9,10,12,13,18,19],[1.5300323537690832,0.9652522100632906,0.7495756001264453,2.0081336229444,0.6428947985542377,0.7409836504433677,0.561982878397376,0.5856157895578966,2.8017082919250824,2.1398280943802774,3.087061307365588])                      |\n","|(20,[4,8,18],[0.9852533261550888,0.6428947985542377,1.0699140471901387])                                                                                                                                                                                             |\n","|(20,[3],[0.9369482318483932])                                                                                                                                                                                                                                        |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 5 rows\n","\n","CPU times: user 577 ms, sys: 205 ms, total: 781 ms\n","Wall time: 5min 50s\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["%%time\n","hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=20)\n","featurizedData = hashingTF.transform(df6)\n","\n","idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n","idfModel = idf.fit(featurizedData)\n","nlpdf = idfModel.transform(featurizedData)\n","nlpdf.select(\"features\").show(5, truncate=False)"]},{"cell_type":"code","execution_count":51,"id":"e93c465d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 307 ms, sys: 71.8 ms, total: 378 ms\n","Wall time: 2min 8s\n"]}],"source":["%%time\n","from pyspark.ml.feature import StringIndexer\n","\n","nlpdf = nlpdf.withColumn(\n","'ratings',\n","F.when((F.col(\"overall\") <= 5.0) & (F.col(\"overall\") > 4.0), \"4-5\") \\\n","    .when((F.col(\"overall\") <= 4.0) & (F.col(\"overall\") > 3.0), \"3-4\") \\\n","    .when((F.col(\"overall\") <= 3.0) & (F.col(\"overall\") > 2.0), \"2-3\") \\\n","    .when((F.col(\"overall\") <= 2.0) & (F.col(\"overall\") > 1.0), \"1-2\") \\\n","    .when((F.col(\"overall\") <= 1.0) & (F.col(\"overall\") > 0), \"0-1\") \\\n",")\n","\n","indexer = StringIndexer(inputCol=\"ratings\", outputCol=\"label\")\n","indexer_model = indexer.fit(nlpdf)\n","nlpdf=indexer_model.transform(nlpdf)"]},{"cell_type":"code","execution_count":52,"id":"85234721","metadata":{},"outputs":[],"source":["#Splitting the data into test and train data\n","train, test = nlpdf.randomSplit(weights=[0.8,0.2], seed=200)"]},{"cell_type":"markdown","id":"dead0224","metadata":{},"source":["### Running Linear Regression, Logistic Regression and Random Forest"]},{"cell_type":"code","execution_count":null,"id":"9bb19e59","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["0.6043846991720532\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 596:======================================================>(87 + 1) / 88]\r"]},{"name":"stdout","output_type":"stream","text":["0.46058148176334546\n","CPU times: user 1.77 s, sys: 587 ms, total: 2.35 s\n","Wall time: 23min 1s\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["%%time\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","# Set parameters for Logistic Regression\n","lgr = LogisticRegression(maxIter=10, featuresCol = 'features', labelCol='label')\n","\n","# Fit the model to the data.\n","lgrm = lgr.fit(train)\n","\n","# Given a dataset, predict each point's label, and show the results.\n","predictions = lgrm.transform(test)\n","\n","#print evaluation metrics\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n","\n","print(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}))\n","print(evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"}))"]},{"cell_type":"code","execution_count":null,"id":"da22cf38","metadata":{},"outputs":[],"source":["100"]},{"cell_type":"code","execution_count":null,"id":"83ffba25","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}