{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fce14dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 3.4.2\n",
      "Apache Spark version: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "#spark sql imports\n",
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f1e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#spark ML imports\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import NGram,CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer\n",
    "from pyspark.ml.regression import LinearRegression,DecisionTreeRegressor,RandomForestRegressor,GBTRegressor\n",
    "from pyspark.ml.classification import LinearSVC,LogisticRegression,DecisionTreeClassifier,RandomForestClassifier,GBTClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator,MulticlassClassificationEvaluator,BinaryClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "#spark NLP imports\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e12d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.enableHiveSupport().appName('AmazonData').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark.conf.set('spark.sql.caseSensitive', True) #Using a SparkSession object named spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbaf875",
   "metadata": {},
   "source": [
    "# Read in All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb278169",
   "metadata": {},
   "outputs": [],
   "source": [
    "AF= 'gs://classificationdata112/classificationdata1122/AMAZON_FASHION.json'\n",
    "AB= 'gs://classificationdata112/classificationdata1122/All_Beauty.json'\n",
    "CSJ= 'gs://classificationdata112/classificationdata1122/Clothing_Shoes_and_Jewelry.json'\n",
    "LB= 'gs://classificationdata112/classificationdata1122/Luxury_Beauty.json'\n",
    "\n",
    "mAF= 'gs://classificationdata112/classificationdata1122/meta_AMAZON_FASHION.json'\n",
    "mAB= 'gs://classificationdata112/classificationdata1122/meta_ALL_Beauty.json'\n",
    "mCSJ= 'gs://classificationdata112/classificationdata1122/meta_Clothing_Shoes_and_Jewelry.json'\n",
    "mLB= 'gs://classificationdata112/classificationdata1122/meta_Luxury_Beauty.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe6635",
   "metadata": {},
   "source": [
    "## Load actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59439719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/13 20:14:35 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df_AF = spark.read.json(AF)\n",
    "df_AF = df_AF.withColumn(\"Category\", F.lit(\"Amazon Fashion\"))\n",
    "df_AF = df_AF.drop(\"reviewerName\",\"style\",\"image\")\n",
    "\n",
    "df_AB = spark.read.json(AB)\n",
    "df_AB = df_AB.withColumn(\"Category\", F.lit(\"All Beauty\"))\n",
    "df_AB = df_AB.drop(\"reviewerName\",\"style\",\"image\")\n",
    "\n",
    "df_CSJ = spark.read.json(CSJ)\n",
    "df_CSJ = df_CSJ.withColumn(\"Category\", F.lit(\"Clothing, Shoes and Jewelery\"))\n",
    "df_CSJ = df_CSJ.drop(\"reviewerName\",\"style\",\"image\")\n",
    "\n",
    "df_LB= spark.read.json(LB)\n",
    "df_LB = df_LB.withColumn(\"Category\", F.lit(\"Luxury Beauty\"))\n",
    "df_LB = df_LB.drop(\"reviewerName\",\"style\",\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598933b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      " |-- verified: boolean (nullable = true)\n",
      " |-- vote: string (nullable = true)\n",
      " |-- Category: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "whole = df_AF.union(df_AB)\n",
    "whole= whole.union(df_CSJ)\n",
    "whole=whole.union(df_LB)\n",
    "whole.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28bd1d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d164c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34121708"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bbb925",
   "metadata": {},
   "source": [
    "## Load Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6681d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mdf_AF = spark.read.json(mAF)\n",
    "mdf_AF = mdf_AF.drop('also_buy','also_view', 'description', 'details', 'feature', 'fit',\n",
    "                    'imageURL','imageURLHighRes', 'similar_item','tech1')\n",
    "\n",
    "mdf_AB = spark.read.json(mAB)\n",
    "mdf_AB = mdf_AB.drop('also_buy','also_view','category', 'description', 'details', 'feature', 'fit',\n",
    "                    'imageURL','imageURLHighRes', 'main_cat','similar_item','tech1', 'tech2')\n",
    "\n",
    "mdf_CSJ = spark.read.json(mCSJ)\n",
    "mdf_CSJ = mdf_CSJ.drop('also_buy','also_view','category', 'description', 'details', 'feature', 'fit',\n",
    "                    'imageURL','imageURLHighRes', 'main_cat','similar_item','tech1', 'tech2')\n",
    "\n",
    "mdf_LB= spark.read.json(mLB)\n",
    "mdf_LB = mdf_LB.drop('also_buy','also_view','category', 'description', 'details', 'feature', 'fit',\n",
    "                    'imageURL','imageURLHighRes', 'main_cat','similar_item','tech1', 'tech2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed60d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_whole= mdf_AF.union(mdf_AB)\n",
    "m_whole= m_whole.union(mdf_CSJ)\n",
    "m_whole=m_whole.union(mdf_LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8692dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- rank: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_whole.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3967ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2916887"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_whole.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042076aa",
   "metadata": {},
   "source": [
    "## Joining Metadata and Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be79c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = whole.join(m_whole,\"asin\",\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12433ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "      <th>Category</th>\n",
       "      <th>brand</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6030555170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I love it</td>\n",
       "      <td>05 5, 2018</td>\n",
       "      <td>AOFKGSCY2NUHR</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1525478400</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>Clothing, Shoes and Jewelery</td>\n",
       "      <td>Lady olga</td>\n",
       "      <td>5 star</td>\n",
       "      <td>$26.80 - $26.94</td>\n",
       "      <td>266,796inClothing,ShoesJewelry(</td>\n",
       "      <td>Lady olga Women's Fleece Bed Jacket On Collar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6030555170</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This bed jacket works well for my mother. It w...</td>\n",
       "      <td>04 22, 2018</td>\n",
       "      <td>A223V2HN62ZKKZ</td>\n",
       "      <td>It washes easily and doesn't shed</td>\n",
       "      <td>1524355200</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>Clothing, Shoes and Jewelery</td>\n",
       "      <td>Lady olga</td>\n",
       "      <td>5 star</td>\n",
       "      <td>$26.80 - $26.94</td>\n",
       "      <td>266,796inClothing,ShoesJewelry(</td>\n",
       "      <td>Lady olga Women's Fleece Bed Jacket On Collar ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  6030555170      4.0                                          I love it   \n",
       "1  6030555170      5.0  This bed jacket works well for my mother. It w...   \n",
       "\n",
       "    reviewTime      reviewerID                            summary  \\\n",
       "0   05 5, 2018   AOFKGSCY2NUHR                         Four Stars   \n",
       "1  04 22, 2018  A223V2HN62ZKKZ  It washes easily and doesn't shed   \n",
       "\n",
       "   unixReviewTime  verified  vote                      Category      brand  \\\n",
       "0      1525478400      True  None  Clothing, Shoes and Jewelery  Lady olga   \n",
       "1      1524355200      True  None  Clothing, Shoes and Jewelery  Lady olga   \n",
       "\n",
       "     date            price                             rank  \\\n",
       "0  5 star  $26.80 - $26.94  266,796inClothing,ShoesJewelry(   \n",
       "1  5 star  $26.80 - $26.94  266,796inClothing,ShoesJewelry(   \n",
       "\n",
       "                                               title  \n",
       "0  Lady olga Women's Fleece Bed Jacket On Collar ...  \n",
       "1  Lady olga Women's Fleece Bed Jacket On Collar ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09649eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:=================================================>      (15 + 2) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning approximate count:34479823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Before cleaning approximate count:{full.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd5e57",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "- drop duplicates:according to 3 columns: reviewerID, asin, unixReviewTime\n",
    "- drop missing values in reviewText:41579 reviews are missing\n",
    "- keep products with at least 10 reviews(so that model can learn better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55007263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=====================================================> (98 + 2) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning approximate count:29814163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# drop duplicates\n",
    "full = full.dropDuplicates(subset=[\"asin\",\"reviewerID\",\"unixReviewTime\"])\n",
    "# drop null\n",
    "full = full.dropna(subset=\"reviewText\")\n",
    "# keep 不那么小众的products\n",
    "winSpecAgg  = Window.partitionBy(\"asin\")\n",
    "finaldf = full.withColumn(\"num\",F.count(F.col(\"reviewerID\")).over(winSpecAgg))\\\n",
    ".where(F.col(\"num\") >= 10) #at least 10 reviews,even if from same author\n",
    "\n",
    "print(f\"After cleaning approximate count:{finaldf.count()}\") #29 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "033927dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append year + month + timestamp columns--dataframe name:df1\n",
    "df1 = finaldf.withColumn(\"timestamp\",F.from_unixtime(\"unixReviewTime\"))\n",
    "df1 = df1.withColumn(\"year\",F.year(\"timestamp\"))\n",
    "df1 = df1.withColumn(\"month\",F.month(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb85f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.select(\"asin\",\"overall\",\"reviewText\",\n",
    "                     \"verified\",\"Category\",\"brand\",\"year\",\"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "456cf3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Function convert rating into binary label\n",
    "@udf(returnType=IntegerType())\n",
    "def convert(num): #overall column cannot be null therefore not need to address this issue in funct\n",
    "    if num > 3:\n",
    "        return 0 #positive--class 0\n",
    "    else: #num < 3\n",
    "        return 1 #negative--class 1 since we care MORE about neg reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0fcd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using \"when\" function\n",
    "# finaldf.withColumn(\"label\",\n",
    "#                    F.when(finaldf[\"overall\"] > 3,1.0).otherwise(0.0)) # after filtering out 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5026e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=====================================================> (98 + 2) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|overall|   count|\n",
      "+-------+--------+\n",
      "|    1.0| 1925720|\n",
      "|    4.0| 4870378|\n",
      "|    3.0| 2522919|\n",
      "|    2.0| 1531057|\n",
      "|    5.0|16710571|\n",
      "+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "finaldf.groupBy(\"overall\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c6500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09154063702065028"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2522919/(1925720+4870378+2522919+1531057+16710571) #9% percent of rating 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d66757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look at rating = 1,2,4,5\n",
    "df3 = df2.filter(finaldf.overall != 3)\n",
    "\n",
    "# add label column\n",
    "df3 = df3.withColumn(\"label\",convert(\"overall\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6daf1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asin',\n",
       " 'overall',\n",
       " 'reviewText',\n",
       " 'verified',\n",
       " 'Category',\n",
       " 'brand',\n",
       " 'year',\n",
       " 'month',\n",
       " 'label']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22acb82f",
   "metadata": {},
   "source": [
    "### Text cleaning 1: filter out reviews that are not in English\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75424e2c",
   "metadata": {},
   "source": [
    "- PIPELINE: `LanguageDetectorDL`\n",
    "- parameters:\n",
    "    - `threshold`:The minimum threshold for the final result--default:0.5;o.w if less than threshold:either neutral or value set in \"thresholdLabel\"\n",
    "    - set lower thresh since `LanguageDetectorDL` works best with text longer than 140 characters.\n",
    "    - but some review is pretty short eg: one word\n",
    "    - `coalesceSentences`:output of all sentences will be averaged to one output instead of one output per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f12b81a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld_wiki_tatoeba_cnn_21 download started this may take some time.\n",
      "Approximate size to download 7.1 MB\n",
      "[ | ]ld_wiki_tatoeba_cnn_21 download started this may take some time.\n",
      "Approximate size to download 7.1 MB\n",
      "Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:==================>                                     (4 + 0) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:================================>                       (7 + 0) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \\ ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:================================>                       (7 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:==================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 19:30:26.255266: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-13 19:30:26.348886: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    ".setInputCol(\"reviewText\")\\\n",
    ".setOutputCol(\"document\")\n",
    "\n",
    "language_detector = LanguageDetectorDL.pretrained(\"ld_wiki_tatoeba_cnn_21\")\\\n",
    ".setInputCols([\"document\"])\\\n",
    ".setOutputCol(\"lang\")\\\n",
    ".setThreshold(0.3)\\\n",
    ".setCoalesceSentences(True)\n",
    "\n",
    "languagePipeline = Pipeline(stages=[\n",
    " documentAssembler, \n",
    " language_detector\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63fd94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF(\"reviewText\")\n",
    "langresults = languagePipeline.fit(empty_df).transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83c88c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langresults = langresults.withColumn(\"language\",F.explode(F.col(\"lang.result\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85fc89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+\n",
      "|        reviewText|language|\n",
      "+------------------+--------+\n",
      "|          Garbage!|      de|\n",
      "| Love Jane Iredale|      it|\n",
      "|         Excellent|      fr|\n",
      "|             Love!|      it|\n",
      "|Excellent product.|      fr|\n",
      "+------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "langresults.filter(langresults.language != \"en\").select(\"reviewText\",\"language\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f9baa",
   "metadata": {},
   "source": [
    "We dont use language detection pipeline to eliminate non-English review since the result is very BAD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62513046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langresults = langresults.withColumn(\"language\",F.explode(F.col(\"lang.result\")))\n",
    "# finalv2 = langresults.filter(langresults.language == \"en\").drop(\"language\",\"document\",\"lang\") #only English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386562ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous:27560645\n",
    "# print(f\"After filtering out non-English reviews,{finalv2.rdd().countApprox()} reviews left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7c46e",
   "metadata": {},
   "source": [
    "### Text cleaning 2: expand contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4475767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', \"i'll\", \"you'll\", \"he'll\", \"she'll\", \"we'll\", \"they'll\", \"i'd\", \"you'd\", \"he'd\", \"she'd\", \"we'd\", \"they'd\", \"i'm\", \"you're\", \"he's\", \"she's\", \"it's\", \"we're\", \"they're\", \"i've\", \"we've\", \"you've\", \"they've\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"shan't\", \"shouldn't\", \"mustn't\", \"can't\", \"couldn't\", 'cannot', 'could', \"here's\", \"how's\", \"let's\", 'ought', \"that's\", \"there's\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", 'would']\n"
     ]
    }
   ],
   "source": [
    "# check whether contraction is included in stopwords\n",
    "# NOT all included! so still need\n",
    "print(stopwords_cleaner.getStopWords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b755914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand contraction\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cf4e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def expand(text):\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    new_text = []\n",
    "    for w in words:\n",
    "        if w in contractions:\n",
    "            new_text.append(contractions[w])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    text = \" \".join(new_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df6e71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.withColumn(\"text\",expand(\"reviewText\"))\n",
    "df4 = df4.drop(\"reviewText\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41a848",
   "metadata": {},
   "source": [
    "Apply stratified sampling according to 0&1 percentage to each category: \n",
    "- used for model selection, vectorizer selection, hyperparameter tuning\n",
    "- 5 Model candidates: `LogisticRegression,LinearSVC,DecisionTreeClassifier,RandomForestClassifier,GBTClassifier`\n",
    "- 2 Vectorizer candidates: Since want to explain the meaning of each columns, only `CountVectorizer` and `TF-IDF with CountVectorizer` can be used\n",
    "    - `HashingTF`: cannot be reversed, infer back from column index to words\n",
    "    - `word2vec`: each column has no meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f18918",
   "metadata": {},
   "source": [
    "## Loop over models & vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c91ba7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/13 20:19:33 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \n",
      "java.lang.InterruptedException\n",
      "\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n",
      "\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n",
      "\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n",
      "\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 18:==============>                                          (3 + 0) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# candidate vectorizers\n",
    "\n",
    "## BEST!!\n",
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"text\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\\\n",
    "      .setLowercase(True) \\\n",
    "      .setCleanupPatterns([\"\"\"[^A-Za-z]\"\"\"]) #only keep alphabet letters #find all numeric useless\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained('lemma_antbnc',\"en\")\\\n",
    "    .setInputCols([\"normalized\"])\\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "# remove stemmer:因为会导致结果不是完整的词\n",
    "# stemmer = Stemmer() \\\n",
    "#       .setInputCols([\"lemma\"]) \\\n",
    "#       .setOutputCol(\"stem\")\n",
    "\n",
    "# 调整顺序\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"lemma\")\\\n",
    "      .setOutputCol(\"cleaned\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "# 后加 因为发现很多no good的评论被分错了 \n",
    "ngrams_cum = NGramGenerator() \\\n",
    "            .setInputCols([\"cleaned\"]) \\\n",
    "            .setOutputCol(\"ngrams\") \\\n",
    "            .setN(3) \\\n",
    "            .setEnableCumulative(True)\\\n",
    "            .setDelimiter(\" \") # Default is space\n",
    "\n",
    "finisher = Finisher() \\\n",
    "      .setInputCols([\"ngrams\"]) \\\n",
    "      .setOutputCols([\"token_features\"]) \\\n",
    "      .setOutputAsArray(True) \\\n",
    "      .setCleanAnnotations(False)\n",
    "\n",
    "# CountVectorizer\n",
    "countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"features\", \n",
    "                               vocabSize=10000, #max size of the vocabulary\n",
    "                               minDF=10) #一个term至少要在这么多不同的docs中出现才会被include\n",
    "\n",
    "pipe_countvec = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            lemmatizer,\n",
    "            stopwords_cleaner,\n",
    "            ngrams_cum,\n",
    "            finisher,\n",
    "            countVectors\n",
    "       ])\n",
    "\n",
    "# TF-IDF with CountVectorizer\n",
    "#countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"rawFeatures\", \n",
    "                               vocabSize=10000, #max size of the vocabulary\n",
    "                               minDF=10) #一个term至少要在这么多不同的docs中出现才会被include\n",
    "\n",
    "#idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=10) #minDocFreq: remove sparse terms\n",
    "# pipe_countidf = Pipeline(\n",
    "#     stages=[document_assembler, \n",
    "#             tokenizer,\n",
    "#             normalizer,\n",
    "#             lemmatizer,\n",
    "#             stopwords_cleaner,\n",
    "#             ngrams_cum,\n",
    "#             finisher,\n",
    "#             countVectors,\n",
    "#             idf\n",
    "#        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced3ffe",
   "metadata": {},
   "source": [
    "Separate out the data into each small category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc386a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "LB = df4.filter(df4.Category == \"Luxury Beauty\")\n",
    "B = df4.filter(df4.Category == \"All Beauty\")\n",
    "FA = df4.filter(df4.Category == \"Amazon Fashion\")\n",
    "C = df4.filter(df4.Category == \"Clothing, Shoes and Jewelery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365b93d",
   "metadata": {},
   "source": [
    "Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8adf0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only take 1% from first three category,0.01% from Clothing category \n",
    "LBsm = LB.sampleBy(\"label\",fractions = {0:0.01,1:0.01},seed=42)\n",
    "Bsm = B.sampleBy(\"label\",fractions = {0:0.01,1:0.01},seed=42)\n",
    "FAsm = FA.sampleBy(\"label\",fractions = {0:0.01,1:0.01},seed=42)\n",
    "Csm = C.sampleBy(\"label\",fractions = {0:0.0001,1:0.0001},seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e98dc0",
   "metadata": {},
   "source": [
    "For text preprocessing illustrative purpose:\n",
    "- transform 100 rows only and show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_fulltfidf = pipe_countidf.fit(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "illu_df = nlp_tfidf_full.transform(df4.limit(2))\n",
    "\n",
    "illu_df.select(\"text\",\"token.result\",\"lemma.result\",\"cleaned.result\",\"ngrams.result\",\"token_features\",\n",
    "              \"features\")\\\n",
    "                .show(2,truncate=300,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab8eac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=====================================================> (98 + 2) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264\n"
     ]
    }
   ],
   "source": [
    "print(Csm.rdd.countApprox(timeout=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eb389ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:======================================================>(99 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4892\n"
     ]
    }
   ],
   "source": [
    "print(LBsm.rdd.countApprox(timeout=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab915514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split to small dataset\n",
    "LB_trainsm = LBsm.sampleBy(\"label\",fractions = {0:0.8,1:0.8},seed=42) #80% training data\n",
    "LB_testsm = LBsm.subtract(LB_trainsm)\n",
    "\n",
    "B_trainsm = Bsm.sampleBy(\"label\",fractions = {0:0.8,1:0.8},seed=42) #80% training data\n",
    "B_testsm = Bsm.subtract(B_trainsm)\n",
    "\n",
    "F_trainsm = FAsm.sampleBy(\"label\",fractions = {0:0.8,1:0.8},seed=42) #80% training data\n",
    "F_testsm = FAsm.subtract(F_trainsm)\n",
    "\n",
    "C_trainsm = Csm.sampleBy(\"label\",fractions = {0:0.8,1:0.8},seed=42) #80% training data\n",
    "C_testsm = FAsm.subtract(C_trainsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a86fc",
   "metadata": {},
   "source": [
    "Luxury Beauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b0c851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate models\n",
    "classifiers = list()\n",
    "classifiers.append([\"Logistic Classifier\",LogisticRegression()])\n",
    "classifiers.append([\"Linear SVM\",LinearSVC()])\n",
    "classifiers.append([\"DecisionTree Classifier\",DecisionTreeClassifier()])\n",
    "classifiers.append([\"RandomForest Classifier\",RandomForestClassifier(numTrees = 10)])\n",
    "classifiers.append([\"GradientBoost Classifier\",GBTClassifier()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7137e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Classifier is training...\n",
      "TF-IDF_CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[4,5,10,12,20,51,60,6...|\n",
      "|       1.0|    0|(1353,[39,40,77,92,201,211,...|\n",
      "|       0.0|    0|(1353,[39,166,748,767],[2.7...|\n",
      "|       0.0|    0|(1353,[1,5,10,12,124,132,35...|\n",
      "|       0.0|    0|(1353,[53,83,156,282],[3.42...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[28,53,69,83,142,246,...|\n",
      "|       1.0|    0|(1353,[38,40,78,92,202,210,...|\n",
      "|       0.0|    0|(1353,[0,1,2,5,7,8,9,12,13,...|\n",
      "|       0.0|    0|            (1353,[224],[1.0])|\n",
      "|       0.0|    0| (1353,[1,5,88],[1.0,1.0,1.0])|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM is training...\n",
      "TF-IDF_CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[0,1,2,5,7,8,9,12,13,...|\n",
      "|       0.0|    0|(1353,[3,16,17,18,24,33,34,...|\n",
      "|       0.0|    0|(1353,[18,142,165,192,313,1...|\n",
      "|       0.0|    0|(1353,[5],[1.54785248222501...|\n",
      "|       1.0|    0|(1353,[4,5,8,13,14,15,17,20...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[28,53,69,83,142,247,...|\n",
      "|       0.0|    0|(1353,[11,22,38,118,151,166...|\n",
      "|       0.0|    0|(1353,[0,1,2,6,7,9,11,12,15...|\n",
      "|       0.0|    0|(1353,[3,16,18,104,495,614,...|\n",
      "|       0.0|    0|(1353,[0,4,6,11,25,69,70,10...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier is training...\n",
      "TF-IDF_CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[3,16,17,18,24,33,34,...|\n",
      "|       0.0|    0|(1353,[223],[4.082293067135...|\n",
      "|       0.0|    0|(1353,[1,166,688],[1.135390...|\n",
      "|       0.0|    1|(1353,[8,60,94,178,235,635,...|\n",
      "|       0.0|    0|(1353,[1,5,87,169,513],[1.1...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[28,53,69,83,143,244,...|\n",
      "|       0.0|    0|(1353,[53,83,156,281],[1.0,...|\n",
      "|       0.0|    0|(1353,[0,4,6,11,25,69,70,10...|\n",
      "|       0.0|    0|(1353,[0,4,7,16,29,30,35,49...|\n",
      "|       0.0|    0|(1353,[0,3,4,16,19,23,37,43...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier is training...\n",
      "TF-IDF_CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[1,5,88],[1.135390021...|\n",
      "|       0.0|    0|(1353,[0,4,5,12,14,26,365,7...|\n",
      "|       0.0|    0|(1353,[225],[4.082293067135...|\n",
      "|       0.0|    0|(1353,[11,22,39,118,151,166...|\n",
      "|       0.0|    0|(1353,[0,1,2,6,7,9,11,12,15...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[2,5,6,20,25,34,45,93...|\n",
      "|       0.0|    0|(1353,[3,158,455],[1.0,1.0,...|\n",
      "|       0.0|    0|(1353,[1,5,10,12,124,131,35...|\n",
      "|       0.0|    0|(1353,[1,166,684],[1.0,1.0,...|\n",
      "|       0.0|    1|(1353,[0,1,2,5,7,8,9,19,21,...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost Classifier is training...\n",
      "TF-IDF_CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[39,40,78,92,201,209,...|\n",
      "|       0.0|    0|(1353,[13,17,23,25,99,259,4...|\n",
      "|       0.0|    1|(1353,[0,1,3,5,9,15,17,67,7...|\n",
      "|       0.0|    0|(1353,[18,151,158,196,312,1...|\n",
      "|       0.0|    0|(1353,[5],[1.54785248222501...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(1353,[39,164,760,777],[1.0...|\n",
      "|       0.0|    0|(1353,[2,5,6,21,25,35,44,96...|\n",
      "|       1.0|    1|(1353,[6,18,45,113,198,211,...|\n",
      "|       1.0|    1|(1353,[8,60,94,178,238,642,...|\n",
      "|       0.0|    0|(1353,[1,5,88,169,533],[1.0...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 s, sys: 7.85 s, total: 27.2 s\n",
      "Wall time: 1h 42min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# loop over models & vectorizers:\n",
    "result = pd.DataFrame()\n",
    "for name,clf in classifiers:\n",
    "    print(f\"{name} is training...\")\n",
    "    # vectorizer\n",
    "    for vect,pipe in zip([\"TF-IDF_CountVectorizer\",\"CountVectorizer\"],\\\n",
    "                         [pipe_countidf,pipe_countvec]):\n",
    "        print(f\"{vect} is running...\")\n",
    "    \n",
    "        t0 = time.time()\n",
    "        nlp_model = pipe.fit(LB_trainsm)\n",
    "        processed_train = nlp_model.transform(LB_trainsm)\n",
    "        processed_test = nlp_model.transform(LB_testsm)\n",
    "\n",
    "        # fit model\n",
    "        clfModel = clf.fit(processed_train)\n",
    "\n",
    "        # predict\n",
    "        predictions = clfModel.transform(processed_test)\n",
    "\n",
    "        # Select example rows to display.\n",
    "        predictions.select(\"prediction\", \"label\", \"features\").show(5,truncate=30)\n",
    "\n",
    "        # Evaluate\n",
    "        bevaluator = BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"rawPrediction\")\n",
    "        mevaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "        # AUC\n",
    "        auc = bevaluator.evaluate(predictions, {bevaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "        # Accuracy\n",
    "        acc = mevaluator.evaluate(predictions, {mevaluator.metricName: \"accuracy\"})\n",
    "\n",
    "        # F1\n",
    "        f1 = mevaluator.evaluate(predictions, {mevaluator.metricName: \"f1\"})\n",
    "\n",
    "        # recall/True Positive Rate\n",
    "        # metricLabel:The class whose metric will be computed in truePositiveRateByLabel|falsePositiveRateByLabel..default=0\n",
    "        # ONLY care about minority class(class=1) recall rate\n",
    "        recall = mevaluator.evaluate(predictions, {mevaluator.metricName: \"recallByLabel\",mevaluator.metricLabel: 1.0})\n",
    "        elapsed = time.time() - t0\n",
    "        # save result\n",
    "        res = [name,vect,auc,acc,f1,recall,elapsed]\n",
    "        result = result.append([res],ignore_index=True)\n",
    "result.columns = [\"Model\",\"Vectorizer\",\"AUC\",\"Accuracy\",\"F1\",\"Recall\",\"Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73161e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.856274</td>\n",
       "      <td>0.877418</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>571.239151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>TF-IDF_CountVectorizer</td>\n",
       "      <td>0.853202</td>\n",
       "      <td>0.872321</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>651.459590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Classifier</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.849145</td>\n",
       "      <td>0.859052</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>580.651742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Classifier</td>\n",
       "      <td>TF-IDF_CountVectorizer</td>\n",
       "      <td>0.835339</td>\n",
       "      <td>0.863136</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>840.606115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoost Classifier</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.794078</td>\n",
       "      <td>0.834090</td>\n",
       "      <td>0.246835</td>\n",
       "      <td>562.866477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoost Classifier</td>\n",
       "      <td>TF-IDF_CountVectorizer</td>\n",
       "      <td>0.780117</td>\n",
       "      <td>0.828776</td>\n",
       "      <td>0.212903</td>\n",
       "      <td>580.609896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest Classifier</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.766871</td>\n",
       "      <td>0.773877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>597.816423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest Classifier</td>\n",
       "      <td>TF-IDF_CountVectorizer</td>\n",
       "      <td>0.749489</td>\n",
       "      <td>0.772141</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>659.699081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree Classifier</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.502504</td>\n",
       "      <td>0.822543</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>550.868778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree Classifier</td>\n",
       "      <td>TF-IDF_CountVectorizer</td>\n",
       "      <td>0.502504</td>\n",
       "      <td>0.820026</td>\n",
       "      <td>0.183544</td>\n",
       "      <td>581.151411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model              Vectorizer       AUC        F1  \\\n",
       "3                Linear SVM         CountVectorizer  0.856274  0.877418   \n",
       "2                Linear SVM  TF-IDF_CountVectorizer  0.853202  0.872321   \n",
       "1       Logistic Classifier         CountVectorizer  0.849145  0.859052   \n",
       "0       Logistic Classifier  TF-IDF_CountVectorizer  0.835339  0.863136   \n",
       "9  GradientBoost Classifier         CountVectorizer  0.794078  0.834090   \n",
       "8  GradientBoost Classifier  TF-IDF_CountVectorizer  0.780117  0.828776   \n",
       "7   RandomForest Classifier         CountVectorizer  0.766871  0.773877   \n",
       "6   RandomForest Classifier  TF-IDF_CountVectorizer  0.749489  0.772141   \n",
       "5   DecisionTree Classifier         CountVectorizer  0.502504  0.822543   \n",
       "4   DecisionTree Classifier  TF-IDF_CountVectorizer  0.502504  0.820026   \n",
       "\n",
       "     Recall        Time  \n",
       "3  0.613497  571.239151  \n",
       "2  0.600000  651.459590  \n",
       "1  0.675325  580.651742  \n",
       "0  0.662338  840.606115  \n",
       "9  0.246835  562.866477  \n",
       "8  0.212903  580.609896  \n",
       "7  0.000000  597.816423  \n",
       "6  0.012987  659.699081  \n",
       "5  0.180645  550.868778  \n",
       "4  0.183544  581.151411  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by=[\"AUC\",\"F1\"],ascending=[False,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90bb8a",
   "metadata": {},
   "source": [
    "- The result suggest we should use Linear SVM + CountVectorizer for Luxury Beauty dataset\n",
    "- Then cross validation to choose best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7521b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nlp_modelsm = pipe_countvec.fit(LB_trainsm)\n",
    "LB_ptrainsm = nlp_modelsm.transform(LB_trainsm)\n",
    "LB_ptestsm = nlp_modelsm.transform(LB_testsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca5196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7cd180a",
   "metadata": {},
   "source": [
    "`LinerSVC` parameters\n",
    "- `regParam`: regularization parameter(how large the penalty is) default=0\n",
    "- `threshold `:The threshold in **binary classification applied to the linear model prediction**. This threshold can be any real number, where Inf will make all predictions 0.0 and -Inf will make all predictions 1.0. default = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51f380",
   "metadata": {},
   "source": [
    "### Try to do hyperparamter tuning\n",
    "- But it is too slow\n",
    "- Give up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ad1048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "linsvc = LinearSVC(maxIter=300) #default=100\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(linsvc.regParam, [0.1, 0.4,0.01]) \\\n",
    "    .addGrid(linsvc.threshold,[0.4,0.5,0.6])\\\n",
    "    .build()\n",
    "\n",
    "# F1.2 for class1 the higher the better\n",
    "# stress more on recall\n",
    "# metricLabel:t\n",
    "crossval = CrossValidator(estimator=linsvc,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                                      metricName = \"fMeasureByLabel\",\n",
    "                                                                     metricLabel = 1,beta = 1.2),numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b62395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cvModel_svc = crossval.fit(LB_ptrainsm) #after choosing best model,use that to predict testing data\n",
    "# print(\"Start testing...\")\n",
    "# predictions = cvModel_log.transform(LB_ptestsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e364af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(cvModel_svc.avgMetrics)) #best training F1.2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841611af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel_svc.bestModel\n",
    "\n",
    "print('Best regParam: ', bestModel._java_obj.getRegParam())\n",
    "print('Best threshold: ', bestModel._java_obj.getThreshold())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bd4ff",
   "metadata": {},
   "source": [
    "Eventually, train model on full dataset with tuuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134110fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "LB_train = LB.sampleBy(\"label\",fractions = {0:0.8,1:0.8},seed=42) #80% training data\n",
    "LB_test = LB.subtract(LB_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2577cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = pipe_countvec.fit(LB_train)\n",
    "LB_ptrain = nlp_model.transform(LB_train)\n",
    "LB_ptest = nlp_model.transform(LB_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a3ad940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 20:32:01 WARN org.apache.spark.scheduler.AsyncEventQueue: Dropped 9585 events from executorManagement since Sat Mar 12 19:55:56 UTC 2022.\n",
      "22/03/12 20:33:01 WARN org.apache.spark.scheduler.AsyncEventQueue: Dropped 48673 events from executorManagement since Sat Mar 12 20:32:01 UTC 2022.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(10000,[3,37,934,2750],[1.0...|\n",
      "|       0.0|    0|(10000,[0,1,4,5,6,7,8,9,15,...|\n",
      "|       0.0|    0|(10000,[1,6,7,10,14,21,27,2...|\n",
      "|       1.0|    0|(10000,[28,55,110,268,550,4...|\n",
      "|       0.0|    1|(10000,[4,9,29,82,118,140,5...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71895:==================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:0.9072989616109896\n",
      "Accuracy:0.916710052270976\n",
      "AUC score:0.9450277328450177\n",
      "Recall:0.5194568301580867\n",
      "Time:682.4030590057373\n",
      "CPU times: user 2.72 s, sys: 1.8 s, total: 4.52 s\n",
      "Wall time: 11min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit model\n",
    "t0 = time.time()\n",
    "SVCbest = LinearSVC(regParam = 0.01,\n",
    "                   threshold = 0.5,\n",
    "                   maxIter=200) \n",
    "bestModel = SVCbest.fit(LB_ptrain)\n",
    "\n",
    "# predict\n",
    "predictions = bestModel.transform(LB_ptest)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5,truncate=30)\n",
    "\n",
    "# Evaluate\n",
    "bevaluator = BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"rawPrediction\")\n",
    "mevaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "# AUC\n",
    "auc = bevaluator.evaluate(predictions, {bevaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "# Accuracy\n",
    "acc = mevaluator.evaluate(predictions, {mevaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# F1\n",
    "f1 = mevaluator.evaluate(predictions, {mevaluator.metricName: \"f1\"})\n",
    "\n",
    "# recall/True Positive Rate\n",
    "# metricLabel:The class whose metric will be computed in truePositiveRateByLabel|falsePositiveRateByLabel..default=0\n",
    "# ONLY care about minority class(class=1) recall rate\n",
    "recall = mevaluator.evaluate(predictions, {mevaluator.metricName: \"recallByLabel\",mevaluator.metricLabel: 1.0})\n",
    "\n",
    "# fit + predict + eval time\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"F1:{f1}\\nAccuracy:{acc}\\nAUC score:{auc}\\nRecall:{recall}\\nTime:{elapsed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfc605",
   "metadata": {},
   "source": [
    "Coefficient Analysis\n",
    "- SVM coefficient:direction means predicted class\n",
    "    - if **weight > 0**: contribute to pos class--in our case:class=1--**Negative review!!**\n",
    "    - if weight < 0: contribute to neg class--class=0--Positive review\n",
    "    - So **OPPOSITE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e91145a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_model = nlp_model.stages[-1]\n",
    "len(count_model.vocabulary) #these number of words/ngram words satisfy minDF requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6346d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.7405971897374637\n"
     ]
    }
   ],
   "source": [
    "# intercept\n",
    "print(\"Intercept: \" + str(bestModel.intercept))\n",
    "\n",
    "# when review contains no word\n",
    "# since intercept is negative:more likely to be negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "92f28c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame(bestModel.coefficients.toArray())\n",
    "coeffs = coeffs.rename(columns = {0:\"coeff\"})\n",
    "coeffs[\"importance\"] = np.abs(coeffs[\"coeff\"])\n",
    "coeffs[\"vocabulary\"] = count_model.vocabulary\n",
    "\n",
    "coeffs.sort_values(by=\"importance\",axis=0,ascending=False,inplace=True)\n",
    "coeffs = coeffs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cf7f0daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "      <th>importance</th>\n",
       "      <th>vocabulary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.205668</td>\n",
       "      <td>3.205668</td>\n",
       "      <td>two star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.268331</td>\n",
       "      <td>2.268331</td>\n",
       "      <td>want love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.049794</td>\n",
       "      <td>2.049794</td>\n",
       "      <td>zero star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.885735</td>\n",
       "      <td>1.885735</td>\n",
       "      <td>disappointing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.834778</td>\n",
       "      <td>1.834778</td>\n",
       "      <td>high hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.740188</td>\n",
       "      <td>1.740188</td>\n",
       "      <td>meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.689804</td>\n",
       "      <td>1.689804</td>\n",
       "      <td>useless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.654980</td>\n",
       "      <td>1.654980</td>\n",
       "      <td>worthless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.646752</td>\n",
       "      <td>1.646752</td>\n",
       "      <td>ineffective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.645215</td>\n",
       "      <td>1.645215</td>\n",
       "      <td>give one star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.561221</td>\n",
       "      <td>1.561221</td>\n",
       "      <td>want like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.519539</td>\n",
       "      <td>1.519539</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.518786</td>\n",
       "      <td>1.518786</td>\n",
       "      <td>less year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.518136</td>\n",
       "      <td>1.518136</td>\n",
       "      <td>get past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.506000</td>\n",
       "      <td>1.506000</td>\n",
       "      <td>scam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.503491</td>\n",
       "      <td>1.503491</td>\n",
       "      <td>yuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.500133</td>\n",
       "      <td>1.500133</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.494281</td>\n",
       "      <td>1.494281</td>\n",
       "      <td>disappointment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.448398</td>\n",
       "      <td>1.448398</td>\n",
       "      <td>send back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.434209</td>\n",
       "      <td>1.434209</td>\n",
       "      <td>might work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.427207</td>\n",
       "      <td>1.427207</td>\n",
       "      <td>price expect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.426332</td>\n",
       "      <td>1.426332</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.421864</td>\n",
       "      <td>1.421864</td>\n",
       "      <td>unusable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.419792</td>\n",
       "      <td>1.419792</td>\n",
       "      <td>disgusting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.416722</td>\n",
       "      <td>1.416722</td>\n",
       "      <td>dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.398513</td>\n",
       "      <td>1.398513</td>\n",
       "      <td>give away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.391291</td>\n",
       "      <td>1.391291</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.387142</td>\n",
       "      <td>1.387142</td>\n",
       "      <td>poorly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.380262</td>\n",
       "      <td>1.380262</td>\n",
       "      <td>dissapointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.363358</td>\n",
       "      <td>1.363358</td>\n",
       "      <td>leave hair dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.361269</td>\n",
       "      <td>1.361269</td>\n",
       "      <td>expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.354320</td>\n",
       "      <td>1.354320</td>\n",
       "      <td>last minute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.345268</td>\n",
       "      <td>1.345268</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.333417</td>\n",
       "      <td>1.333417</td>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.326805</td>\n",
       "      <td>1.326805</td>\n",
       "      <td>even close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.319935</td>\n",
       "      <td>1.319935</td>\n",
       "      <td>doesnt work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.316144</td>\n",
       "      <td>1.316144</td>\n",
       "      <td>garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.304520</td>\n",
       "      <td>1.304520</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.292792</td>\n",
       "      <td>1.292792</td>\n",
       "      <td>stay away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.277552</td>\n",
       "      <td>1.277552</td>\n",
       "      <td>sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.274887</td>\n",
       "      <td>1.274887</td>\n",
       "      <td>horribly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.274846</td>\n",
       "      <td>1.274846</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.265721</td>\n",
       "      <td>1.265721</td>\n",
       "      <td>didnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.262770</td>\n",
       "      <td>1.262770</td>\n",
       "      <td>may work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.249304</td>\n",
       "      <td>1.249304</td>\n",
       "      <td>money back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1.247405</td>\n",
       "      <td>1.247405</td>\n",
       "      <td>stop work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.246036</td>\n",
       "      <td>1.246036</td>\n",
       "      <td>sadly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.228078</td>\n",
       "      <td>1.228078</td>\n",
       "      <td>rip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.223768</td>\n",
       "      <td>1.223768</td>\n",
       "      <td>make hair dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.222318</td>\n",
       "      <td>1.222318</td>\n",
       "      <td>much prefer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.218233</td>\n",
       "      <td>1.218233</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.201196</td>\n",
       "      <td>1.201196</td>\n",
       "      <td>advertising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.200033</td>\n",
       "      <td>1.200033</td>\n",
       "      <td>trash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.198773</td>\n",
       "      <td>1.198773</td>\n",
       "      <td>misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.191969</td>\n",
       "      <td>1.191969</td>\n",
       "      <td>runny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.187523</td>\n",
       "      <td>1.187523</td>\n",
       "      <td>expect well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.183755</td>\n",
       "      <td>1.183755</td>\n",
       "      <td>ugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.182195</td>\n",
       "      <td>1.182195</td>\n",
       "      <td>good true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.156084</td>\n",
       "      <td>1.156084</td>\n",
       "      <td>hype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.149514</td>\n",
       "      <td>1.149514</td>\n",
       "      <td>half full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.148503</td>\n",
       "      <td>1.148503</td>\n",
       "      <td>really much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.143798</td>\n",
       "      <td>1.143798</td>\n",
       "      <td>nope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.142774</td>\n",
       "      <td>1.142774</td>\n",
       "      <td>come break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.139429</td>\n",
       "      <td>1.139429</td>\n",
       "      <td>great first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.135241</td>\n",
       "      <td>1.135241</td>\n",
       "      <td>bum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.123849</td>\n",
       "      <td>1.123849</td>\n",
       "      <td>refund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.103649</td>\n",
       "      <td>1.103649</td>\n",
       "      <td>unfortunately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1.096703</td>\n",
       "      <td>1.096703</td>\n",
       "      <td>suction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.088379</td>\n",
       "      <td>1.088379</td>\n",
       "      <td>nothing hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.085773</td>\n",
       "      <td>1.085773</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.075754</td>\n",
       "      <td>1.075754</td>\n",
       "      <td>great review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.075655</td>\n",
       "      <td>1.075655</td>\n",
       "      <td>hold charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.070122</td>\n",
       "      <td>1.070122</td>\n",
       "      <td>pretty sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.069680</td>\n",
       "      <td>1.069680</td>\n",
       "      <td>keep try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.063446</td>\n",
       "      <td>1.063446</td>\n",
       "      <td>gritty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1.059690</td>\n",
       "      <td>1.059690</td>\n",
       "      <td>see change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.059624</td>\n",
       "      <td>1.059624</td>\n",
       "      <td>lesson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.054843</td>\n",
       "      <td>1.054843</td>\n",
       "      <td>wont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.047009</td>\n",
       "      <td>1.047009</td>\n",
       "      <td>absolutely nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1.041013</td>\n",
       "      <td>1.041013</td>\n",
       "      <td>give two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.036625</td>\n",
       "      <td>1.036625</td>\n",
       "      <td>defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.026501</td>\n",
       "      <td>1.026501</td>\n",
       "      <td>try time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.024447</td>\n",
       "      <td>1.024447</td>\n",
       "      <td>product old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.024238</td>\n",
       "      <td>1.024238</td>\n",
       "      <td>alas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.024149</td>\n",
       "      <td>1.024149</td>\n",
       "      <td>hard use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.021839</td>\n",
       "      <td>1.021839</td>\n",
       "      <td>also work well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.021426</td>\n",
       "      <td>1.021426</td>\n",
       "      <td>may good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.012377</td>\n",
       "      <td>1.012377</td>\n",
       "      <td>low heat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.006839</td>\n",
       "      <td>1.006839</td>\n",
       "      <td>bummer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.005176</td>\n",
       "      <td>1.005176</td>\n",
       "      <td>overpriced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.002394</td>\n",
       "      <td>1.002394</td>\n",
       "      <td>save money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.999855</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>notice change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.998487</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>badly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.990884</td>\n",
       "      <td>0.990884</td>\n",
       "      <td>well job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.988993</td>\n",
       "      <td>0.988993</td>\n",
       "      <td>nowhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.984948</td>\n",
       "      <td>0.984948</td>\n",
       "      <td>never work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.984059</td>\n",
       "      <td>0.984059</td>\n",
       "      <td>less month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.981869</td>\n",
       "      <td>0.981869</td>\n",
       "      <td>might well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.979548</td>\n",
       "      <td>0.979548</td>\n",
       "      <td>streaky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.979498</td>\n",
       "      <td>chip easily</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coeff  importance          vocabulary\n",
       "0    3.205668    3.205668            two star\n",
       "2    2.268331    2.268331           want love\n",
       "5    2.049794    2.049794           zero star\n",
       "6    1.885735    1.885735       disappointing\n",
       "7    1.834778    1.834778           high hope\n",
       "11   1.740188    1.740188                 meh\n",
       "15   1.689804    1.689804             useless\n",
       "17   1.654980    1.654980           worthless\n",
       "18   1.646752    1.646752         ineffective\n",
       "19   1.645215    1.645215       give one star\n",
       "21   1.561221    1.561221           want like\n",
       "24   1.519539    1.519539        disappointed\n",
       "25   1.518786    1.518786           less year\n",
       "26   1.518136    1.518136            get past\n",
       "27   1.506000    1.506000                scam\n",
       "28   1.503491    1.503491                yuck\n",
       "29   1.500133    1.500133             unhappy\n",
       "30   1.494281    1.494281      disappointment\n",
       "32   1.448398    1.448398           send back\n",
       "34   1.434209    1.434209          might work\n",
       "35   1.427207    1.427207        price expect\n",
       "36   1.426332    1.426332              return\n",
       "37   1.421864    1.421864            unusable\n",
       "38   1.419792    1.419792          disgusting\n",
       "39   1.416722    1.416722        dissatisfied\n",
       "41   1.398513    1.398513           give away\n",
       "42   1.391291    1.391291            horrible\n",
       "43   1.387142    1.387142              poorly\n",
       "46   1.380262    1.380262        dissapointed\n",
       "48   1.363358    1.363358      leave hair dry\n",
       "49   1.361269    1.361269              expire\n",
       "50   1.354320    1.354320         last minute\n",
       "51   1.345268    1.345268            terrible\n",
       "56   1.333417    1.333417               shame\n",
       "57   1.326805    1.326805          even close\n",
       "59   1.319935    1.319935         doesnt work\n",
       "60   1.316144    1.316144             garbage\n",
       "63   1.304520    1.304520             concept\n",
       "64   1.292792    1.292792           stay away\n",
       "66   1.277552    1.277552               sorry\n",
       "67   1.274887    1.274887            horribly\n",
       "68   1.274846    1.274846               awful\n",
       "70   1.265721    1.265721               didnt\n",
       "73   1.262770    1.262770            may work\n",
       "76   1.249304    1.249304          money back\n",
       "77   1.247405    1.247405           stop work\n",
       "78   1.246036    1.246036               sadly\n",
       "81   1.228078    1.228078                 rip\n",
       "84   1.223768    1.223768       make hair dry\n",
       "85   1.222318    1.222318         much prefer\n",
       "86   1.218233    1.218233                poor\n",
       "90   1.201196    1.201196         advertising\n",
       "92   1.200033    1.200033               trash\n",
       "93   1.198773    1.198773          misleading\n",
       "94   1.191969    1.191969               runny\n",
       "95   1.187523    1.187523         expect well\n",
       "97   1.183755    1.183755                 ugh\n",
       "98   1.182195    1.182195           good true\n",
       "105  1.156084    1.156084                hype\n",
       "107  1.149514    1.149514           half full\n",
       "108  1.148503    1.148503         really much\n",
       "109  1.143798    1.143798                nope\n",
       "111  1.142774    1.142774          come break\n",
       "112  1.139429    1.139429         great first\n",
       "114  1.135241    1.135241                 bum\n",
       "116  1.123849    1.123849              refund\n",
       "120  1.103649    1.103649       unfortunately\n",
       "122  1.096703    1.096703             suction\n",
       "126  1.088379    1.088379        nothing hair\n",
       "127  1.085773    1.085773               empty\n",
       "132  1.075754    1.075754        great review\n",
       "133  1.075655    1.075655         hold charge\n",
       "137  1.070122    1.070122         pretty sure\n",
       "138  1.069680    1.069680            keep try\n",
       "140  1.063446    1.063446              gritty\n",
       "142  1.059690    1.059690          see change\n",
       "143  1.059624    1.059624              lesson\n",
       "147  1.054843    1.054843                wont\n",
       "153  1.047009    1.047009  absolutely nothing\n",
       "156  1.041013    1.041013            give two\n",
       "158  1.036625    1.036625           defective\n",
       "161  1.026501    1.026501            try time\n",
       "164  1.024447    1.024447         product old\n",
       "165  1.024238    1.024238                alas\n",
       "166  1.024149    1.024149            hard use\n",
       "167  1.021839    1.021839      also work well\n",
       "169  1.021426    1.021426            may good\n",
       "171  1.012377    1.012377            low heat\n",
       "172  1.006839    1.006839              bummer\n",
       "173  1.005176    1.005176          overpriced\n",
       "176  1.002394    1.002394          save money\n",
       "177  0.999855    0.999855       notice change\n",
       "178  0.998487    0.998487               badly\n",
       "181  0.990884    0.990884            well job\n",
       "182  0.988993    0.988993             nowhere\n",
       "185  0.984948    0.984948          never work\n",
       "186  0.984059    0.984059          less month\n",
       "190  0.981869    0.981869          might well\n",
       "192  0.979548    0.979548             streaky\n",
       "193  0.979498    0.979498         chip easily"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coeff>0:contribute to pos class--negative reviews\n",
    "neg = coeffs[coeffs[\"coeff\"]>0].sort_values(by=\"importance\",ascending=False)\n",
    "neg.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8d297",
   "metadata": {},
   "source": [
    "Beauty\n",
    "- no more looping through vectorizer:since `CountVectorizer` is proven to be better than `TF-IDF` for Luxury Beauty data on all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa920f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Classifier is training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Classifier is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 18:41:20 WARN org.apache.spark.scheduler.AsyncEventQueue: Dropped 36377 events from executorManagement since Sat Mar 12 18:33:38 UTC 2022.\n",
      "[Stage 66463:==================================================>(165 + 1) / 166]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Classifier is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0| (830,[1,2,100],[1.0,1.0,1.0])|\n",
      "|       0.0|    0|(830,[1,2,4,6,8,11,14,16,19...|\n",
      "|       0.0|    0|               (830,[5],[1.0])|\n",
      "|       0.0|    0|(830,[0,7,17,50,59],[1.0,1....|\n",
      "|       0.0|    0|(830,[0,1,2,3,6,16,24,28,29...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Logistic Classifier is evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM is training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 18:51:11 WARN org.apache.spark.scheduler.AsyncEventQueue: Dropped 9501 events from executorManagement since Sat Mar 12 18:41:20 UTC 2022.\n",
      "[Stage 67413:==================================================>(165 + 1) / 166]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|               (830,[5],[1.0])|\n",
      "|       0.0|    0|(830,[3,10,30,44,45,54,100,...|\n",
      "|       0.0|    0|(830,[3,39,201],[1.0,1.0,1.0])|\n",
      "|       0.0|    0|(830,[6,20,29,39,45,172,205...|\n",
      "|       0.0|    0|(830,[5,56,117],[1.0,1.0,1.0])|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Linear SVM is evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier is training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0| (830,[1,2,100],[1.0,1.0,1.0])|\n",
      "|       0.0|    0|(830,[3,10,30,44,46,53,99,1...|\n",
      "|       0.0|    0|(830,[1,2,4,6,8,11,14,16,19...|\n",
      "|       0.0|    0|(830,[1,2,3,6,7,8,9,13,15,4...|\n",
      "|       0.0|    0|(830,[3,39,202],[1.0,1.0,1.0])|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "DecisionTree Classifier is evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier is training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67761:==================================================>(165 + 1) / 166]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(830,[1,2,4,6,8,11,14,16,19...|\n",
      "|       0.0|    0|               (830,[5],[1.0])|\n",
      "|       0.0|    0|(830,[0,5,12,13,18,25,36,37...|\n",
      "|       0.0|    0|(830,[3,10,30,44,45,53,101,...|\n",
      "|       0.0|    0|(830,[6,20,29,39,45,172,204...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RandomForest Classifier is evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost Classifier is training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost Classifier is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 19:19:32 WARN org.apache.spark.scheduler.AsyncEventQueue: Dropped 26312 events from executorManagement since Sat Mar 12 18:51:11 UTC 2022.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost Classifier is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(830,[5,56,117],[1.0,1.0,1.0])|\n",
      "|       0.0|    0| (830,[1,2,101],[1.0,1.0,1.0])|\n",
      "|       0.0|    0|(830,[1,2,4,6,8,11,14,16,19...|\n",
      "|       0.0|    1|(830,[0,1,9,15,22,37,38,45,...|\n",
      "|       0.0|    0|               (830,[5],[1.0])|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "GradientBoost Classifier is evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.54 s, sys: 3.75 s, total: 12.3 s\n",
      "Wall time: 47min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# loop over models\n",
    "result = pd.DataFrame()\n",
    "for name,clf in classifiers:\n",
    "    print(f\"{name} is training...\")\n",
    "    \n",
    "    # text processing\n",
    "    t0 = time.time()\n",
    "    nlp_model = pipe_countvec.fit(B_trainsm)\n",
    "    processed_train = nlp_model.transform(B_trainsm)\n",
    "    processed_test = nlp_model.transform(B_testsm)\n",
    "\n",
    "    # fit model\n",
    "    print(f\"{name} is fitting...\")\n",
    "    clfModel = clf.fit(processed_train)\n",
    "\n",
    "    # predict\n",
    "    print(f\"{name} is predicting...\")\n",
    "    predictions = clfModel.transform(processed_test)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"label\", \"features\").show(5,truncate=30)\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"{name} is evaluating...\")\n",
    "    bevaluator = BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"rawPrediction\")\n",
    "    mevaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "    # AUC\n",
    "    auc = bevaluator.evaluate(predictions, {bevaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "    # Accuracy\n",
    "    acc = mevaluator.evaluate(predictions, {mevaluator.metricName: \"accuracy\"})\n",
    "\n",
    "    # F1\n",
    "    f1 = mevaluator.evaluate(predictions, {mevaluator.metricName: \"f1\"})\n",
    "\n",
    "    # recall/True Positive Rate\n",
    "    # metricLabel:The class whose metric will be computed in truePositiveRateByLabel|falsePositiveRateByLabel..default=0\n",
    "    # ONLY care about minority class(class=1) recall rate\n",
    "    recall = mevaluator.evaluate(predictions, {mevaluator.metricName: \"recallByLabel\",mevaluator.metricLabel: 1.0})\n",
    "    elapsed = time.time() - t0 # fit+predict+eval\n",
    "    \n",
    "    # save result\n",
    "    res = [name,auc,acc,f1,recall,elapsed]\n",
    "    result = result.append([res],ignore_index=True)\n",
    "    \n",
    "result.columns = [\"Model\",\"AUC\",\"Accuracy\",\"F1\",\"Recall\",\"Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8535edca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.832525</td>\n",
       "      <td>0.875614</td>\n",
       "      <td>0.873719</td>\n",
       "      <td>0.523256</td>\n",
       "      <td>569.634468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoost Classifier</td>\n",
       "      <td>0.791008</td>\n",
       "      <td>0.870704</td>\n",
       "      <td>0.845017</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>508.874130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Classifier</td>\n",
       "      <td>0.784817</td>\n",
       "      <td>0.842881</td>\n",
       "      <td>0.849538</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>625.177967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest Classifier</td>\n",
       "      <td>0.741384</td>\n",
       "      <td>0.859247</td>\n",
       "      <td>0.794198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>596.295657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree Classifier</td>\n",
       "      <td>0.540653</td>\n",
       "      <td>0.860884</td>\n",
       "      <td>0.828266</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>535.738722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model       AUC  Accuracy        F1    Recall  \\\n",
       "1                Linear SVM  0.832525  0.875614  0.873719  0.523256   \n",
       "4  GradientBoost Classifier  0.791008  0.870704  0.845017  0.232558   \n",
       "0       Logistic Classifier  0.784817  0.842881  0.849538  0.558140   \n",
       "3   RandomForest Classifier  0.741384  0.859247  0.794198  0.000000   \n",
       "2   DecisionTree Classifier  0.540653  0.860884  0.828266  0.162791   \n",
       "\n",
       "         Time  \n",
       "1  569.634468  \n",
       "4  508.874130  \n",
       "0  625.177967  \n",
       "3  596.295657  \n",
       "2  535.738722  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by=[\"AUC\",\"F1\"],ascending=[False,False])\n",
    "\n",
    "# linear SVM recall slightly lower than logistic regression(lower in AUC,ACC,F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf798d",
   "metadata": {},
   "source": [
    "- Linear SVM is the best model for Beauty category\n",
    "- retrain on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef4a5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "B_train = B.sampleBy(\"label\",fractions = {0:0.8,1:0.8},seed=42) #80% training data\n",
    "B_test = B.subtract(B_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a7f6d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nlp_model = pipe_countvec.fit(B_train)\n",
    "B_ptrain = nlp_model.transform(B_train)\n",
    "B_ptest = nlp_model.transform(B_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04934a",
   "metadata": {},
   "source": [
    "Retrain model on full Beauty dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "57c0f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 21:02:46 WARN org.apache.spark.scheduler.AsyncEventQueue: Dropped 10601 events from executorManagement since Sat Mar 12 20:33:01 UTC 2022.\n",
      "22/03/12 21:03:46 WARN org.apache.spark.scheduler.AsyncEventQueue: Dropped 53060 events from executorManagement since Sat Mar 12 21:02:46 UTC 2022.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------------------+\n",
      "|prediction|label|                      features|\n",
      "+----------+-----+------------------------------+\n",
      "|       0.0|    0|(10000,[0,9,14,28,31,40,44,...|\n",
      "|       0.0|    0|(10000,[0,3,4,6,8,9,12,25,2...|\n",
      "|       0.0|    0|(10000,[2,26,55,340,564,110...|\n",
      "|       0.0|    0|(10000,[3,7,11,19,32,48,53,...|\n",
      "|       0.0|    1|(10000,[70,288,2042],[1.0,1...|\n",
      "+----------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73632:==========================================>          (17 + 4) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:0.8918806837169349\n",
      "Accuracy:0.9027089159189555\n",
      "AUC score:0.9381077272401492\n",
      "Recall:0.5148956817079088\n",
      "Time:779.1942629814148\n",
      "CPU times: user 2.65 s, sys: 1.81 s, total: 4.46 s\n",
      "Wall time: 12min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit model\n",
    "t0 = time.time()\n",
    "SVCbest = LinearSVC(regParam = 0.01,\n",
    "                   threshold = 0.5,\n",
    "                   maxIter=200) \n",
    "bestModel = SVCbest.fit(B_ptrain)\n",
    "\n",
    "# predict\n",
    "predictions = bestModel.transform(B_ptest)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5,truncate=30)\n",
    "\n",
    "# Evaluate\n",
    "bevaluator = BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"rawPrediction\")\n",
    "mevaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "# AUC\n",
    "auc = bevaluator.evaluate(predictions, {bevaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "# Accuracy\n",
    "acc = mevaluator.evaluate(predictions, {mevaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# F1\n",
    "f1 = mevaluator.evaluate(predictions, {mevaluator.metricName: \"f1\"})\n",
    "\n",
    "# recall/True Positive Rate\n",
    "# metricLabel:The class whose metric will be computed in truePositiveRateByLabel|falsePositiveRateByLabel..default=0\n",
    "# ONLY care about minority class(class=1) recall rate\n",
    "recall = mevaluator.evaluate(predictions, {mevaluator.metricName: \"recallByLabel\",mevaluator.metricLabel: 1.0})\n",
    "\n",
    "# fit + predict + eval time\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"F1:{f1}\\nAccuracy:{acc}\\nAUC score:{auc}\\nRecall:{recall}\\nTime:{elapsed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e29671",
   "metadata": {},
   "source": [
    "Coefficients Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "38e184d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.6260157480633176\n"
     ]
    }
   ],
   "source": [
    "# intercept\n",
    "print(\"Intercept: \" + str(bestModel.intercept))\n",
    "\n",
    "# when review contains no word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "32e7a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame(bestModel.coefficients.toArray())\n",
    "coeffs = coeffs.rename(columns = {0:\"coeff\"})\n",
    "coeffs[\"importance\"] = np.abs(coeffs[\"coeff\"])\n",
    "coeffs[\"vocabulary\"] = count_model.vocabulary\n",
    "\n",
    "coeffs.sort_values(by=\"importance\",axis=0,ascending=False,inplace=True)\n",
    "coeffs = coeffs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "549c9d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "      <th>importance</th>\n",
       "      <th>vocabulary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.383875</td>\n",
       "      <td>3.383875</td>\n",
       "      <td>lacquer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.174090</td>\n",
       "      <td>2.174090</td>\n",
       "      <td>couple week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.942986</td>\n",
       "      <td>1.942986</td>\n",
       "      <td>look pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.841766</td>\n",
       "      <td>1.841766</td>\n",
       "      <td>surely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.827211</td>\n",
       "      <td>1.827211</td>\n",
       "      <td>love always</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.743920</td>\n",
       "      <td>1.743920</td>\n",
       "      <td>good facial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.688967</td>\n",
       "      <td>1.688967</td>\n",
       "      <td>dryness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.686986</td>\n",
       "      <td>1.686986</td>\n",
       "      <td>curl last day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.661698</td>\n",
       "      <td>1.661698</td>\n",
       "      <td>hair heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.634447</td>\n",
       "      <td>1.634447</td>\n",
       "      <td>pevonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.626016</td>\n",
       "      <td>1.626016</td>\n",
       "      <td>use day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.612824</td>\n",
       "      <td>1.612824</td>\n",
       "      <td>nowhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.599715</td>\n",
       "      <td>1.599715</td>\n",
       "      <td>ten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.599440</td>\n",
       "      <td>1.599440</td>\n",
       "      <td>skin feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.597122</td>\n",
       "      <td>1.597122</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.583119</td>\n",
       "      <td>1.583119</td>\n",
       "      <td>ulta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.577241</td>\n",
       "      <td>1.577241</td>\n",
       "      <td>correctly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.575197</td>\n",
       "      <td>1.575197</td>\n",
       "      <td>protect sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.574952</td>\n",
       "      <td>1.574952</td>\n",
       "      <td>smell much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.545803</td>\n",
       "      <td>1.545803</td>\n",
       "      <td>pour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.524296</td>\n",
       "      <td>1.524296</td>\n",
       "      <td>thick hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.507483</td>\n",
       "      <td>1.507483</td>\n",
       "      <td>good work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.506598</td>\n",
       "      <td>1.506598</td>\n",
       "      <td>bottle use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.494702</td>\n",
       "      <td>1.494702</td>\n",
       "      <td>magical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.493002</td>\n",
       "      <td>1.493002</td>\n",
       "      <td>read lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.472878</td>\n",
       "      <td>1.472878</td>\n",
       "      <td>love eyeliner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.461240</td>\n",
       "      <td>1.461240</td>\n",
       "      <td>shiny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.453944</td>\n",
       "      <td>1.453944</td>\n",
       "      <td>drip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.441151</td>\n",
       "      <td>1.441151</td>\n",
       "      <td>love everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.430922</td>\n",
       "      <td>1.430922</td>\n",
       "      <td>matte finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.428882</td>\n",
       "      <td>1.428882</td>\n",
       "      <td>well cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.416792</td>\n",
       "      <td>1.416792</td>\n",
       "      <td>remove eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.405541</td>\n",
       "      <td>1.405541</td>\n",
       "      <td>apply product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.397983</td>\n",
       "      <td>1.397983</td>\n",
       "      <td>face scrub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.397578</td>\n",
       "      <td>1.397578</td>\n",
       "      <td>ever find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.395609</td>\n",
       "      <td>1.395609</td>\n",
       "      <td>require</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.393350</td>\n",
       "      <td>1.393350</td>\n",
       "      <td>one dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.382113</td>\n",
       "      <td>1.382113</td>\n",
       "      <td>cast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.379220</td>\n",
       "      <td>1.379220</td>\n",
       "      <td>paul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.374329</td>\n",
       "      <td>1.374329</td>\n",
       "      <td>old spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.372342</td>\n",
       "      <td>1.372342</td>\n",
       "      <td>cheaply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.363992</td>\n",
       "      <td>1.363992</td>\n",
       "      <td>stuff work well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.359429</td>\n",
       "      <td>1.359429</td>\n",
       "      <td>occasionally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.355835</td>\n",
       "      <td>1.355835</td>\n",
       "      <td>size travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.343440</td>\n",
       "      <td>1.343440</td>\n",
       "      <td>skin react</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.338373</td>\n",
       "      <td>1.338373</td>\n",
       "      <td>save hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.323188</td>\n",
       "      <td>1.323188</td>\n",
       "      <td>spend extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.321331</td>\n",
       "      <td>1.321331</td>\n",
       "      <td>abba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.311798</td>\n",
       "      <td>1.311798</td>\n",
       "      <td>wash every</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.304377</td>\n",
       "      <td>1.304377</td>\n",
       "      <td>use proraso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.303246</td>\n",
       "      <td>1.303246</td>\n",
       "      <td>costly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.297179</td>\n",
       "      <td>1.297179</td>\n",
       "      <td>past month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.288308</td>\n",
       "      <td>1.288308</td>\n",
       "      <td>use face wash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1.287162</td>\n",
       "      <td>1.287162</td>\n",
       "      <td>flawlessly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.279457</td>\n",
       "      <td>1.279457</td>\n",
       "      <td>good brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.275912</td>\n",
       "      <td>1.275912</td>\n",
       "      <td>buy see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.274140</td>\n",
       "      <td>1.274140</td>\n",
       "      <td>nice lather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.269123</td>\n",
       "      <td>1.269123</td>\n",
       "      <td>roche posay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.266752</td>\n",
       "      <td>1.266752</td>\n",
       "      <td>product protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.261587</td>\n",
       "      <td>1.261587</td>\n",
       "      <td>try return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.260803</td>\n",
       "      <td>1.260803</td>\n",
       "      <td>heel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.257383</td>\n",
       "      <td>1.257383</td>\n",
       "      <td>expensive buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.250774</td>\n",
       "      <td>1.250774</td>\n",
       "      <td>iron love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.246228</td>\n",
       "      <td>1.246228</td>\n",
       "      <td>run finger hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.236904</td>\n",
       "      <td>1.236904</td>\n",
       "      <td>try good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.235811</td>\n",
       "      <td>1.235811</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.235211</td>\n",
       "      <td>1.235211</td>\n",
       "      <td>creme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.231756</td>\n",
       "      <td>1.231756</td>\n",
       "      <td>obviously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.230498</td>\n",
       "      <td>1.230498</td>\n",
       "      <td>good self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.230449</td>\n",
       "      <td>1.230449</td>\n",
       "      <td>primarily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.230378</td>\n",
       "      <td>1.230378</td>\n",
       "      <td>add bit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1.229791</td>\n",
       "      <td>1.229791</td>\n",
       "      <td>product awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.226496</td>\n",
       "      <td>1.226496</td>\n",
       "      <td>keratin treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.220832</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>leavein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.219936</td>\n",
       "      <td>1.219936</td>\n",
       "      <td>give one star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.213610</td>\n",
       "      <td>1.213610</td>\n",
       "      <td>lauder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.204163</td>\n",
       "      <td>1.204163</td>\n",
       "      <td>great take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.203487</td>\n",
       "      <td>1.203487</td>\n",
       "      <td>taste like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.199171</td>\n",
       "      <td>1.199171</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.197203</td>\n",
       "      <td>1.197203</td>\n",
       "      <td>overall like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.195314</td>\n",
       "      <td>1.195314</td>\n",
       "      <td>awesome color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.193141</td>\n",
       "      <td>1.193141</td>\n",
       "      <td>purse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.193113</td>\n",
       "      <td>1.193113</td>\n",
       "      <td>aluminum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.192240</td>\n",
       "      <td>1.192240</td>\n",
       "      <td>couple time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.185819</td>\n",
       "      <td>1.185819</td>\n",
       "      <td>work beautifully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.185614</td>\n",
       "      <td>1.185614</td>\n",
       "      <td>oribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.180423</td>\n",
       "      <td>1.180423</td>\n",
       "      <td>essie polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.179288</td>\n",
       "      <td>1.179288</td>\n",
       "      <td>skin also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.176292</td>\n",
       "      <td>1.176292</td>\n",
       "      <td>debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.175553</td>\n",
       "      <td>1.175553</td>\n",
       "      <td>suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.174521</td>\n",
       "      <td>1.174521</td>\n",
       "      <td>scent go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.165265</td>\n",
       "      <td>1.165265</td>\n",
       "      <td>twice much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.158114</td>\n",
       "      <td>1.158114</td>\n",
       "      <td>reviewer say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.157043</td>\n",
       "      <td>1.157043</td>\n",
       "      <td>hesitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1.152226</td>\n",
       "      <td>1.152226</td>\n",
       "      <td>well sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1.148706</td>\n",
       "      <td>1.148706</td>\n",
       "      <td>buy run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.146040</td>\n",
       "      <td>1.146040</td>\n",
       "      <td>masque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1.144819</td>\n",
       "      <td>1.144819</td>\n",
       "      <td>well dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1.143895</td>\n",
       "      <td>1.143895</td>\n",
       "      <td>hair easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1.142921</td>\n",
       "      <td>1.142921</td>\n",
       "      <td>commit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coeff  importance         vocabulary\n",
       "0    3.383875    3.383875            lacquer\n",
       "5    2.174090    2.174090        couple week\n",
       "9    1.942986    1.942986        look pretty\n",
       "13   1.841766    1.841766             surely\n",
       "14   1.827211    1.827211        love always\n",
       "19   1.743920    1.743920        good facial\n",
       "21   1.688967    1.688967            dryness\n",
       "22   1.686986    1.686986      curl last day\n",
       "24   1.661698    1.661698         hair heavy\n",
       "26   1.634447    1.634447            pevonia\n",
       "27   1.626016    1.626016            use day\n",
       "30   1.612824    1.612824            nowhere\n",
       "32   1.599715    1.599715                ten\n",
       "33   1.599440    1.599440          skin feel\n",
       "34   1.597122    1.597122                pad\n",
       "35   1.583119    1.583119               ulta\n",
       "36   1.577241    1.577241          correctly\n",
       "37   1.575197    1.575197        protect sun\n",
       "38   1.574952    1.574952         smell much\n",
       "41   1.545803    1.545803               pour\n",
       "45   1.524296    1.524296         thick hair\n",
       "49   1.507483    1.507483          good work\n",
       "50   1.506598    1.506598         bottle use\n",
       "52   1.494702    1.494702            magical\n",
       "54   1.493002    1.493002           read lot\n",
       "57   1.472878    1.472878      love eyeliner\n",
       "58   1.461240    1.461240              shiny\n",
       "59   1.453944    1.453944               drip\n",
       "61   1.441151    1.441151    love everything\n",
       "65   1.430922    1.430922       matte finish\n",
       "66   1.428882    1.428882         well cheap\n",
       "69   1.416792    1.416792         remove eye\n",
       "71   1.405541    1.405541      apply product\n",
       "72   1.397983    1.397983         face scrub\n",
       "73   1.397578    1.397578          ever find\n",
       "74   1.395609    1.395609            require\n",
       "76   1.393350    1.393350            one dry\n",
       "81   1.382113    1.382113               cast\n",
       "83   1.379220    1.379220               paul\n",
       "85   1.374329    1.374329          old spice\n",
       "87   1.372342    1.372342            cheaply\n",
       "91   1.363992    1.363992    stuff work well\n",
       "93   1.359429    1.359429       occasionally\n",
       "94   1.355835    1.355835        size travel\n",
       "102  1.343440    1.343440         skin react\n",
       "105  1.338373    1.338373          save hair\n",
       "107  1.323188    1.323188        spend extra\n",
       "108  1.321331    1.321331               abba\n",
       "111  1.311798    1.311798         wash every\n",
       "115  1.304377    1.304377        use proraso\n",
       "116  1.303246    1.303246             costly\n",
       "119  1.297179    1.297179         past month\n",
       "121  1.288308    1.288308      use face wash\n",
       "122  1.287162    1.287162         flawlessly\n",
       "123  1.279457    1.279457         good brand\n",
       "125  1.275912    1.275912            buy see\n",
       "127  1.274140    1.274140        nice lather\n",
       "129  1.269123    1.269123        roche posay\n",
       "130  1.266752    1.266752    product protect\n",
       "134  1.261587    1.261587         try return\n",
       "135  1.260803    1.260803               heel\n",
       "137  1.257383    1.257383      expensive buy\n",
       "140  1.250774    1.250774          iron love\n",
       "141  1.246228    1.246228    run finger hair\n",
       "143  1.236904    1.236904           try good\n",
       "145  1.235811    1.235811              sleep\n",
       "147  1.235211    1.235211              creme\n",
       "152  1.231756    1.231756          obviously\n",
       "153  1.230498    1.230498          good self\n",
       "154  1.230449    1.230449          primarily\n",
       "155  1.230378    1.230378            add bit\n",
       "156  1.229791    1.229791    product awesome\n",
       "157  1.226496    1.226496  keratin treatment\n",
       "158  1.220832    1.220832            leavein\n",
       "159  1.219936    1.219936      give one star\n",
       "164  1.213610    1.213610             lauder\n",
       "169  1.204163    1.204163         great take\n",
       "170  1.203487    1.203487         taste like\n",
       "174  1.199171    1.199171               user\n",
       "175  1.197203    1.197203       overall like\n",
       "177  1.195314    1.195314      awesome color\n",
       "178  1.193141    1.193141              purse\n",
       "179  1.193113    1.193113           aluminum\n",
       "181  1.192240    1.192240        couple time\n",
       "187  1.185819    1.185819   work beautifully\n",
       "189  1.185614    1.185614              oribe\n",
       "192  1.180423    1.180423       essie polish\n",
       "194  1.179288    1.179288          skin also\n",
       "198  1.176292    1.176292             debate\n",
       "199  1.175553    1.175553               suit\n",
       "200  1.174521    1.174521           scent go\n",
       "205  1.165265    1.165265         twice much\n",
       "211  1.158114    1.158114       reviewer say\n",
       "212  1.157043    1.157043           hesitant\n",
       "216  1.152226    1.152226     well sensitive\n",
       "218  1.148706    1.148706            buy run\n",
       "219  1.146040    1.146040             masque\n",
       "220  1.144819    1.144819           well dry\n",
       "222  1.143895    1.143895          hair easy\n",
       "223  1.142921    1.142921             commit"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coeff>0:contribute to pos class--negative reviews\n",
    "neg = coeffs[coeffs[\"coeff\"]>0].sort_values(by=\"importance\",ascending=False)\n",
    "neg.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27db615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "663f95bb",
   "metadata": {},
   "source": [
    "## Specific Product analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e8550",
   "metadata": {},
   "source": [
    "Specific brands: B00005J55C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834718a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific = df2.filter(df2.asin == \"B00005JS5C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7815a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_2012 = specific.filter(specific.year < 2012)\n",
    "after_2012 = specific.filter(specific.year >= 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eb717bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:=====================================================>  (71 + 4) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | THank YOu! I had been wanting something like this forever, I thought it only existed in my dreams!!!!!                                                                                                   \n",
      " overall    | 5.0                                                                                                                                                                                                      \n",
      " year       | 2005                                                                                                                                                                                                     \n",
      " month      | 8                                                                                                                                                                                                        \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | I bought this for my wife because she complained of using a razor.  6 months later the thing just decides to stop working for no apparent reason.  I'm not going to even bother complaining, just buy... \n",
      " overall    | 2.0                                                                                                                                                                                                      \n",
      " year       | 2002                                                                                                                                                                                                     \n",
      " month      | 4                                                                                                                                                                                                        \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "before_2012.select(\"reviewText\",\"overall\",\"year\",\"month\").show(2,vertical=True,truncate=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39457705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:=================================================>      (66 + 9) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | It works.                                                                                                                                                \n",
      " overall    | 5.0                                                                                                                                                      \n",
      " year       | 2018                                                                                                                                                     \n",
      " month      | 1                                                                                                                                                        \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | It does the job but I wish it could shave closer. So, I want to try maybe a men's electric razor so maybe I could skip the shaving part when I use this. \n",
      " overall    | 4.0                                                                                                                                                      \n",
      " year       | 2013                                                                                                                                                     \n",
      " month      | 5                                                                                                                                                        \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "after_2012.select(\"reviewText\",\"overall\",\"year\",\"month\").show(2,vertical=True,truncate=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ed27bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_2012.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4079fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2153"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_2012.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c047be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:===================>                                     (4 + 0) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# YAKE pipeline\n",
    "stopwords = StopWordsCleaner().getStopWords()\n",
    "document = DocumentAssembler() \\\n",
    "    .setInputCol(\"reviewText\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "token = Tokenizer() \\\n",
    "    .setInputCols(\"sentence\") \\\n",
    "    .setOutputCol(\"token\") \n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained('lemma_antbnc',\"en\")\\\n",
    "    .setInputCols([\"token\"])\\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "keywords = YakeKeywordExtraction() \\\n",
    "    .setInputCols(\"lemma\") \\\n",
    "    .setOutputCol(\"keywords\") \\\n",
    "    .setMinNGrams(1) \\\n",
    "    .setMaxNGrams(3)\\\n",
    "    .setNKeywords(20)\\\n",
    "    .setStopWords(stopwords)\n",
    "\n",
    "yake_pipeline = Pipeline(stages=[document, sentenceDetector, token,lemmatizer, keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20492791",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF(\"reviewText\")\n",
    "\n",
    "yake_Model = yake_pipeline.fit(empty_df)\n",
    "before_kws = yake_Model.transform(before_2012)\n",
    "after_kws = yake_Model.transform(after_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ab24a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:=====================================================>  (71 + 4) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | THank YOu! I had been wanting something like this forever, I thought it only existed in my dreams!!!!!                                                                                                   \n",
      " result     | [thank, want, something, like, forever, think, exist, dream, want something, something like, want something like, like this forever]                                                                     \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | I bought this for my wife because she complained of using a razor.  6 months later the thing just decides to stop working for no apparent reason.  I'm not going to even bother complaining, just buy... \n",
      " result     | [buy, wife, complain, use, razor, month, late, thing, decide, stop, work, apparent, reason, go, even, bother, complain, buy, norelco, something, stop work, bother complain]                             \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "before_kws.select(\"reviewText\",\"keywords.result\").show(2,vertical=True,truncate=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8322667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 106:====================================================>  (71 + 4) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | It works.                                                                                                                                                                                    \n",
      " result     | [work]                                                                                                                                                                                       \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " reviewText | It does the job but I wish it could shave closer. So, I want to try maybe a men's electric razor so maybe I could skip the shaving part when I use this.                                     \n",
      " result     | [job, wish, shave, close, want, try, maybe, electric, razor, maybe, skip, shave, part, use, shave close, try maybe, electric razor, shave part, want to try, razor so maybe, skip the shave] \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "after_kws.select(\"reviewText\",\"keywords.result\").show(2,vertical=True,truncate=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08317c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "before_pdf = before_kws.select(\"keywords.result\",\"brand\").toPandas()\n",
    "before_pdf.to_csv(\"gs://classificationdata112/spec_before.csv\",index=False)\n",
    "\n",
    "after_pdf = after_kws.select(\"keywords.result\",\"brand\").toPandas()\n",
    "after_pdf.to_csv(\"gs://classificationdata112/spec_after.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98801b",
   "metadata": {},
   "source": [
    "## Digress to brands analysis\n",
    "- TOP brands: Lots of review & high star rating\n",
    "    - which we can learn from\n",
    "- LOW brands: Lots of review BUT low star rating\n",
    "    - how to help them improve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d0c81",
   "metadata": {},
   "source": [
    "### Beauty brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a967b181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asin', 'overall', 'verified', 'Category', 'brand', 'label', 'text']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d950b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP brands\n",
    "top_brands = B.groupBy(\"brand\")\\\n",
    "            .agg(F.count(\"asin\").alias(\"cnt\"),\\\n",
    "                 F.avg(\"overall\").alias(\"avg_rating\"))\\\n",
    "            .orderBy(F.col(\"cnt\").desc(),F.col(\"avg_rating\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "135938cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOW brands\n",
    "# Add a threshold to num of counts\n",
    "# <500 reviews are not informative\n",
    "bot_brands = B.groupBy(\"brand\")\\\n",
    "            .agg(F.count(\"asin\").alias(\"cnt\"),\\\n",
    "                 F.avg(\"overall\").alias(\"avg_rating\"))\\\n",
    "            .where(F.col(\"cnt\")>500).where(~F.col(\"brand\").isNull())\\\n",
    "            .orderBy(F.col(\"avg_rating\").asc(),F.col(\"cnt\").desc()) #rating small->big & review cnt big->small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e65b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:=====================================================> (97 + 3) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+-----------------+\n",
      "|          brand|  cnt|       avg_rating|\n",
      "+---------------+-----+-----------------+\n",
      "|               |50069|3.907407777267371|\n",
      "|       Waterpik|15950|4.494796238244514|\n",
      "|Philips Norelco|11243|4.140087165347327|\n",
      "|           null| 4822| 4.81625881377022|\n",
      "|          Astra| 4356| 4.63475665748393|\n",
      "|Pre de Provence| 3102|4.545454545454546|\n",
      "|       Aquaphor| 2772|4.695887445887446|\n",
      "+---------------+-----+-----------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_brands.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dbb70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(brand=''),\n",
       " Row(brand='Waterpik'),\n",
       " Row(brand='Philips Norelco'),\n",
       " Row(brand=None),\n",
       " Row(brand='Astra'),\n",
       " Row(brand='Pre de Provence'),\n",
       " Row(brand='Aquaphor')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5 = top_brands.select(\"brand\").take(7) #list of rows\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dce7e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Waterpik', 'Philips Norelco', 'Astra', 'Pre de Provence', 'Aquaphor']\n"
     ]
    }
   ],
   "source": [
    "top5_brands = [r[\"brand\"] for r in top5]\n",
    "top5_brands.pop(0) #pop null value\n",
    "top5_brands.pop(2) #pop None\n",
    "print(top5_brands)\n",
    "\n",
    "top5_text = B.filter(B.brand.isin(top5_brands)).select(\"brand\",\"text\",\"overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f1e8aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:===================================================>  (96 + 4) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------------------+\n",
      "|      brand| cnt|        avg_rating|\n",
      "+-----------+----+------------------+\n",
      "|    Keyzone| 538|3.3717472118959106|\n",
      "|    General| 955|3.5518324607329843|\n",
      "|      Tojwi| 582|3.6443298969072164|\n",
      "|  Remington|1030| 3.681553398058252|\n",
      "|      Crest|1532|3.6906005221932117|\n",
      "|    Hittime| 645| 3.710077519379845|\n",
      "|ArtNaturals| 697| 3.781922525107604|\n",
      "+-----------+----+------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bot_brands.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b314e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select brands based on both rating & count\n",
    "bot5_brands = [\"Remington\",\"Crest\",\"General\",\"ArtNaturals\",\"Hittime\"]\n",
    "bot5_text = B.filter(B.brand.isin(bot5_brands)).select(\"brand\",\"text\",\"overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f7802a",
   "metadata": {},
   "source": [
    "Extract keywords using \"YAKE\"--Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction algorithm.\n",
    "- **not rely on dictionaries nor thesauri, neither is trained against any corpora**. Instead, it follows an unsupervised approach which **builds upon features extracted from the text**\n",
    "- thus applicable to documents written in different languages without the need for further knowledge.\n",
    "- Lower the score better the keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87dda094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# YAKE pipeline\n",
    "stopwords = StopWordsCleaner().getStopWords()\n",
    "document = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "token = Tokenizer() \\\n",
    "    .setInputCols(\"sentence\") \\\n",
    "    .setOutputCol(\"token\") \n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained('lemma_antbnc',\"en\")\\\n",
    "    .setInputCols([\"token\"])\\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "keywords = YakeKeywordExtraction() \\\n",
    "    .setInputCols(\"lemma\") \\\n",
    "    .setOutputCol(\"keywords\") \\\n",
    "    .setMinNGrams(1) \\\n",
    "    .setMaxNGrams(3)\\\n",
    "    .setNKeywords(20)\\\n",
    "    .setStopWords(stopwords)\n",
    "\n",
    "yake_pipeline = Pipeline(stages=[document, sentenceDetector, token,lemmatizer, keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59595ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "yake_Model = yake_pipeline.fit(empty_df)\n",
    "top5_kws = yake_Model.transform(top5_text)\n",
    "bot5_kws = yake_Model.transform(bot5_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "724fb92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 132:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------+\n",
      "|result  |score              |sentence|\n",
      "+--------+-------------------+--------+\n",
      "|replace |0.33314794283653154|0       |\n",
      "|old     |0.32121341354607774|0       |\n",
      "|norelco |0.3434944862586114 |0       |\n",
      "|battery |0.7400971684685155 |0       |\n",
      "|die     |0.7400971684685155 |0       |\n",
      "|replace |0.33314794283653154|0       |\n",
      "|make    |0.7822897391776581 |1       |\n",
      "|sure    |0.7822897391776581 |1       |\n",
      "|pick    |0.7822897391776581 |1       |\n",
      "|model   |0.7822897391776581 |1       |\n",
      "|use     |0.35793488361448167|1       |\n",
      "|either  |0.7822897391776581 |1       |\n",
      "|recharge|0.7822897391776581 |1       |\n",
      "|plug    |0.7822897391776581 |1       |\n",
      "|directly|0.7822897391776581 |1       |\n",
      "|nice    |0.23550875425103696|2       |\n",
      "|turbo   |0.8066379851555865 |2       |\n",
      "|nice    |0.23550875425103696|2       |\n",
      "|get     |0.8066379851555865 |2       |\n",
      "|cut     |0.8066379851555865 |2       |\n",
      "+--------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_kws.withColumn(\"tmp\",\n",
    "                    F.explode(\"keywords\"))\\\n",
    "                    .select(\"tmp.*\").select(\"result\",\"metadata.score\",\"metadata.sentence\").show(20,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e339160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|i purchased this to replace my old norelco, only because the batteries died and they could not be replaced. so i made sure to pick a model that could be used by either recharging or plugged in directly. the vacuum is nice, the turbo is nice, but i got it because of the adjustable cutting length and the ease of use. it is nicer than my old norelco, and it even trims a little better too :)|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_kws.select(\"text\").show(1,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b9386b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save to GCS\n",
    "top5b_pdf = top5_kws.select(\"keywords.result\",\"brand\").toPandas()\n",
    "top5b_pdf.to_csv(\"gs://classificationdata112/brand_top5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14c8d54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 150:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+--------+\n",
      "|result     |score             |sentence|\n",
      "+-----------+------------------+--------+\n",
      "|shaver     |0.744138854039555 |0       |\n",
      "|many       |0.3707058744476707|0       |\n",
      "|year       |0.744138854039555 |0       |\n",
      "|work       |0.3707058744476707|0       |\n",
      "|wonderfully|0.744138854039555 |0       |\n",
      "|finally    |0.7858651376729936|1       |\n",
      "|die        |0.7858651376729936|1       |\n",
      "|find       |0.3707058744476707|1       |\n",
      "|another    |0.7858651376729936|1       |\n",
      "|one        |0.7858651376729936|1       |\n",
      "|well       |0.3402730661923907|1       |\n",
      "|try        |0.8099106823316435|2       |\n",
      "|many       |0.3707058744476707|2       |\n",
      "|different  |0.8099106823316435|2       |\n",
      "|style      |0.8099106823316435|2       |\n",
      "|find       |0.3707058744476707|2       |\n",
      "|happy      |0.8258854983232315|3       |\n",
      "|work       |0.3707058744476707|3       |\n",
      "|well       |0.3402730661923907|3       |\n",
      "|many year  |1.2307152451676047|0       |\n",
      "+-----------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bot5_kws.withColumn(\"tmp\",\n",
    "                    F.explode(\"keywords\"))\\\n",
    "                    .select(\"tmp.*\").select(\"result\",\"metadata.score\",\"metadata.sentence\").show(20,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4391d2e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 158:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|i had this shaver for many years and it worked wonderfully. when it finally \"died\" i could not find another one that did as well. so after trying many different styles, i found this. i am so happy and it works so well.|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bot5_kws.select(\"text\").show(1,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70e37392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save to GCS\n",
    "bot5b_pdf = bot5_kws.select(\"keywords.result\",\"brand\").toPandas()\n",
    "bot5b_pdf.to_csv(\"gs://classificationdata112/brand_bot5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4f024",
   "metadata": {},
   "source": [
    "### Luxury Beauty brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "efdeaee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = FA.groupBy(\"brand\")\\\n",
    "            .agg(F.count(\"asin\").alias(\"cnt\"),\\\n",
    "                 F.avg(\"overall\").alias(\"avg_rating\"))\\\n",
    "            .where(~F.col(\"brand\").isNull())\\\n",
    "            .orderBy(F.col(\"cnt\").desc(),F.col(\"avg_rating\").desc()) #rating small->big & review cnt big->small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea06237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(brand='Allegra K', cnt=11805, avg_rating=3.7612875900042355),\n",
       " Row(brand='i play.', cnt=9283, avg_rating=4.543789723149843),\n",
       " Row(brand='MJ Metals Jewelry', cnt=4890, avg_rating=4.828220858895706),\n",
       " Row(brand='Pierced Owl', cnt=3341, avg_rating=3.454354983537863),\n",
       " Row(brand='Scarleton', cnt=2665, avg_rating=4.300562851782364),\n",
       " Row(brand='Ninimour', cnt=2107, avg_rating=3.3663977218794496),\n",
       " Row(brand='BRYK', cnt=1854, avg_rating=4.347357065803668),\n",
       " Row(brand='LaSuiveur', cnt=1814, avg_rating=3.8092613009922824),\n",
       " Row(brand='Vans', cnt=1714, avg_rating=4.477829638273046),\n",
       " Row(brand='BodyJ4You', cnt=1691, avg_rating=4.377291543465405),\n",
       " Row(brand='Amazon Collection', cnt=1652, avg_rating=4.4291767554479415),\n",
       " Row(brand='Zmart', cnt=1490, avg_rating=3.92751677852349),\n",
       " Row(brand='HDE', cnt=1403, avg_rating=3.736992159657876),\n",
       " Row(brand='Fawziya', cnt=1375, avg_rating=4.637090909090909),\n",
       " Row(brand='WearMe Pro', cnt=1345, avg_rating=4.2698884758364315)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e1119be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP brands\n",
    "top5_brands = [\"MJ Metals Jewelry\",\"i play.\",\"Fawziya\",\"Vans\",\"Amazon Collection\"] #Fashion的评分普遍偏低--打分人数多不代表rating高\n",
    "top5_text = FA.filter(FA.brand.isin(top5_brands)).select(\"brand\",\"text\",\"overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ecad8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dataframe\n",
    "top5_kws_fa = yake_Model.transform(top5_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "706d7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save to GCS\n",
    "top5_fa = top5_kws_fa.select(\"keywords.result\",\"brand\").toPandas()\n",
    "top5_fa.to_csv(\"gs://classificationdata112/brand_top5_FA.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ed12710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low brands\n",
    "bot5_brands = [\"Allegra K\",\"LaSuiveur\",\"Ninimour\",\"Pierced Owl\",\"HDE\"] #4分以下的\n",
    "bot5_text = FA.filter(FA.brand.isin(bot5_brands)).select(\"brand\",\"text\",\"overall\")\n",
    "\n",
    "# transform dataframe\n",
    "bot5_kws_fa = yake_Model.transform(bot5_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "185f7c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save to GCS\n",
    "bot5_fa = bot5_kws_fa.select(\"keywords.result\",\"brand\").toPandas()\n",
    "bot5_fa.to_csv(\"gs://classificationdata112/brand_bot5_FA.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ed436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
